{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1bd28adb8509702c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-13T18:01:35.509374Z",
     "start_time": "2024-11-13T18:01:35.506051Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom utilities\n",
    "import NO_utils_multiple\n",
    "import NO_utils\n",
    "\n",
    "# Standard libraries\n",
    "import sys\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "# Scientific computing\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# Deep learning - PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.fft\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "from torch.utils.data import (\n",
    "    DataLoader, Dataset, TensorDataset,\n",
    "    random_split, ConcatDataset\n",
    ")\n",
    "from torchvision import transforms\n",
    "\n",
    "# Neural operator specific\n",
    "from neuralop.models import FNO, FNO2d, TFNO, TFNO2d\n",
    "from neuralop import Trainer, LpLoss, H1Loss\n",
    "\n",
    "# Data processing and visualization\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Progress tracking\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Force garbage collection to release file handles\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5becb675",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_dir = os.getcwd()\n",
    "reserved_dataset_path = os.path.join(current_dir, 'data', 'reduced', 'set reserved', 'reserved_dataset1_ws4_bs2_f32.pt')\n",
    "reserved_dataset = torch.load(reserved_dataset_path)\n",
    "\n",
    "print(\"Reserved Dataset :\")\n",
    "print(f\"Type: {type(reserved_dataset)}\")\n",
    "print(f\"Length: {len(reserved_dataset)}\")\n",
    "if hasattr(reserved_dataset, 'tensors'):\n",
    "    for i, tensor in enumerate(reserved_dataset.tensors):\n",
    "        print(f\"Tensor {i}: shape {tensor.shape}, dtype {tensor.dtype}\")\n",
    "\n",
    "\n",
    "# Get info about first sample to understand structure\n",
    "first_sample = reserved_dataset[0]\n",
    "if isinstance(first_sample, tuple):\n",
    "    print(\"\\nFirst sample structure:\")\n",
    "    for i, item in enumerate(first_sample):\n",
    "        if torch.is_tensor(item):\n",
    "            print(f\"Item {i}: shape {item.shape}, dtype {item.dtype}\")\n",
    "        else:\n",
    "            print(f\"Item {i}: type {type(item)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8260d15b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample(input_tensor, output_tensor):\n",
    "    \"\"\"\n",
    "    Visualize input and output tensors from a single sample.\n",
    "    \n",
    "    Args:\n",
    "        input_tensor: Tensor of shape (3, H, W) containing input components\n",
    "        output_tensor: Tensor of shape (4, H, W) containing output components\n",
    "    \"\"\"\n",
    "    # Create figure for input components\n",
    "    fig1 = plt.figure(figsize=(16, 4))\n",
    "\n",
    "    # Plot input tensor components (1x3 subplot)\n",
    "    for i in range(3):\n",
    "        plt.subplot(1, 3, i+1)\n",
    "        im = plt.imshow(input_tensor[i].abs().numpy())\n",
    "        plt.colorbar(im)\n",
    "        plt.title(f'Input Component {i+1}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Create figure for output components \n",
    "    fig2 = plt.figure(figsize=(16, 4))\n",
    "\n",
    "    # Plot output tensor components (1x4 subplot)\n",
    "    for i in range(4):\n",
    "        plt.subplot(1, 4, i+1)\n",
    "        im = plt.imshow(output_tensor[i].abs().numpy())\n",
    "        plt.colorbar(im)\n",
    "        plt.title(f'Output Component {i+1}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fe0e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a random sample from the dataset\n",
    "random_idx = np.random.randint(0, len(reserved_dataset))\n",
    "sample = reserved_dataset[random_idx]\n",
    "\n",
    "# Extract input and output tensors from the sample\n",
    "input_tensor = sample[0]  # First element is input\n",
    "output_tensor = sample[1] # Second element is output\n",
    "\n",
    "print(f\"Visualizing random sample {random_idx}\")\n",
    "visualize_sample(input_tensor, output_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a53b90bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_models(model_paths):\n",
    "    \"\"\"\n",
    "    Evaluate multiple models on the dataset and report average L1 error for each.\n",
    "    \n",
    "    Args:\n",
    "        model_paths: List of relative paths to model weight files\n",
    "    \"\"\"\n",
    "    # Store results\n",
    "    results = {}\n",
    "    \n",
    "    for model_path in model_paths:\n",
    "        print(f\"\\nEvaluating model: {model_path}\")\n",
    "        \n",
    "        # Load model weights\n",
    "        state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "        \n",
    "        # Initialize new model and load weights\n",
    "        model = NONet()\n",
    "        model.load_state_dict(state_dict)\n",
    "        model.eval()\n",
    "        \n",
    "        # Calculate average L1 error across dataset\n",
    "        total_l1_error = 0.0\n",
    "        num_samples = len(reserved_dataset)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for sample in reserved_dataset:\n",
    "                input_tensor = sample[0]\n",
    "                target_tensor = sample[1]\n",
    "                \n",
    "                # Get model prediction\n",
    "                pred_tensor = model(input_tensor.unsqueeze(0)).squeeze(0)\n",
    "                \n",
    "                # Calculate L1 error\n",
    "                l1_error = torch.mean(torch.abs(pred_tensor - target_tensor))\n",
    "                total_l1_error += l1_error.item()\n",
    "        \n",
    "        # Store average error\n",
    "        avg_l1_error = total_l1_error / num_samples\n",
    "        results[model_path] = avg_l1_error\n",
    "        print(f\"Average L1 Error: {avg_l1_error:.6f}\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example usage:\n",
    "model_paths = [\n",
    "    'model_weights/RAdam_20241113_004451/RAdam_epoch_3_lr=0.01_weight_decay=0.pt',\n",
    "    # Add more model paths here\n",
    "]\n",
    "results = evaluate_models(model_paths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-11-13T18:01:36.107924Z"
    },
    "collapsed": true,
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hz283\\AppData\\Local\\Temp\\ipykernel_60800\\2814157227.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(model_path, map_location=torch.device('cpu'))\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "plot_model_weights_histogram('model_weights/RAdam_20241113_004451/RAdam_epoch_3_lr=0.01_weight_decay=0.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a36296b1b2ed1b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
