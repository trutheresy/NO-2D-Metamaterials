{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n\n# A simple Darcy-Flow dataset\nAn intro to the small Darcy-Flow example dataset we ship with the package.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import the library\nWe first import our `neuralop` library and required dependencies.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\nfrom neuralop.data.datasets import load_darcy_flow_small\nfrom neuralop.layers.embeddings import GridEmbedding2D"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load the dataset\nTraining samples are 16x16 and we load testing samples at both \n16x16 and 32x32 (to test resolution invariance).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "train_loader, test_loaders, data_processor = load_darcy_flow_small(\n        n_train=100, batch_size=4, \n        test_resolutions=[16, 32], n_tests=[50, 50], test_batch_sizes=[4, 2],\n        )\n\ntrain_dataset = train_loader.dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualizing the data\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for res, test_loader in test_loaders.items():\n    print(res)\n    # Get first batch\n    batch = next(iter(test_loader))\n    x = batch['x']\n    y = batch['y']\n\n    print(f'Testing samples for res {res} have shape {x.shape[1:]}')\n\n\ndata = train_dataset[0]\nx = data['x']\ny = data['y']\n\nprint(f'Training samples have shape {x.shape[1:]}')\n\n\n# Which sample to view\nindex = 0\n\ndata = train_dataset[index]\ndata = data_processor.preprocess(data, batched=False)\n\n# The first step of the default FNO model is a grid-based\n# positional embedding. We will add it manually here to\n# visualize the channels appended by this embedding.\npositional_embedding = GridEmbedding2D(in_channels=1)\n# at train time, data will be collated with a batch dim.\n# we create a batch dim to pass into the embedding, then re-squeeze\nx = positional_embedding(data['x'].unsqueeze(0)).squeeze(0)\ny = data['y']\nfig = plt.figure(figsize=(7, 7))\nax = fig.add_subplot(2, 2, 1)\nax.imshow(x[0], cmap='gray')\nax.set_title('input x')\nax = fig.add_subplot(2, 2, 2)\nax.imshow(y.squeeze())\nax.set_title('input y')\nax = fig.add_subplot(2, 2, 3)\nax.imshow(x[1])\nax.set_title('x: 1st pos embedding')\nax = fig.add_subplot(2, 2, 4)\nax.imshow(x[2])\nax.set_title('x: 2nd pos embedding')\nfig.suptitle('Visualizing one input sample', y=0.98)\nplt.tight_layout()\nfig.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}