{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Reduced PyTorch to MATLAB Dataset Converter (Inverse Function)\n",
        "\n",
        "This notebook converts reduced PyTorch `.pt` format back to MATLAB `.mat` format.\n",
        "\n",
        "**Features:**\n",
        "- Loads reduced PyTorch dataset from a folder\n",
        "- Reconstructs full MATLAB structure from reduced data\n",
        "- Reconstructs EIGENVECTOR_DATA from reduced displacements using indices\n",
        "- Reconstructs EIGENVALUE_DATA (fills with zeros if not available)\n",
        "- Reconstructs designs with all panes\n",
        "- Saves as MATLAB v7.3 `.mat` file\n",
        "\n",
        "**Note:** This is the inverse function of `matlab_to_reduced_pt.ipynb`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import torch\n",
        "import h5py\n",
        "from pathlib import Path\n",
        "import os\n",
        "import time\n",
        "\n",
        "# Custom utilities\n",
        "import NO_utils\n",
        "import NO_utils_multiple\n",
        "\n",
        "print(\"Libraries imported successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set your input (reduced PT dataset folder) and output (MATLAB .mat file) paths:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION - Modify these as needed\n",
        "# ============================================================================\n",
        "\n",
        "# Path to reduced PT dataset folder (contains .pt files)\n",
        "pt_input_folder = r\"D:\\Research\\NO-2D-Metamaterials\\data\\dispersion_binarized_1_predictions\"\n",
        "\n",
        "# Output folder (will be created with _mat suffix)\n",
        "output_base_folder = Path(pt_input_folder).parent\n",
        "output_folder_name = Path(pt_input_folder).name + \"_mat\"\n",
        "output_folder = output_base_folder / output_folder_name\n",
        "\n",
        "# Output MATLAB .mat file path (inside the output folder)\n",
        "matlab_output_file = output_folder / f\"{Path(pt_input_folder).name}.mat\"\n",
        "\n",
        "# ============================================================================\n",
        "\n",
        "# Convert to Path objects\n",
        "pt_input_path = Path(pt_input_folder)\n",
        "matlab_output_path = Path(matlab_output_file)\n",
        "\n",
        "print(f\"PT input folder: {pt_input_path}\")\n",
        "print(f\"Output folder: {output_folder}\")\n",
        "print(f\"MATLAB output file: {matlab_output_path}\")\n",
        "\n",
        "# Validate input\n",
        "if not pt_input_path.exists():\n",
        "    raise FileNotFoundError(f\"Input folder does not exist: {pt_input_path}\")\n",
        "\n",
        "# Create output directory if needed\n",
        "output_folder.mkdir(parents=True, exist_ok=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Inverse Conversion Function\n",
        "\n",
        "Define a function to convert reduced PT format back to MATLAB format:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def interleave_arrays(arr1, arr2, dim):\n",
        "    \"\"\"\n",
        "    Interleave two arrays along a specified dimension (inverse of split_array).\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    arr1 : np.ndarray\n",
        "        First array (elements at even indices)\n",
        "    arr2 : np.ndarray\n",
        "        Second array (elements at odd indices)\n",
        "    dim : int\n",
        "        Dimension along which to interleave\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    np.ndarray : Interleaved array\n",
        "    \"\"\"\n",
        "    if arr1.shape != arr2.shape:\n",
        "        raise ValueError(f\"Arrays must have the same shape. Got {arr1.shape} and {arr2.shape}\")\n",
        "    \n",
        "    shape = list(arr1.shape)\n",
        "    if shape[dim] % 2 != 0:\n",
        "        raise ValueError(f\"Dimension {dim} must be even for interleaving\")\n",
        "    \n",
        "    # Create output shape with doubled dimension\n",
        "    output_shape = shape.copy()\n",
        "    output_shape[dim] = shape[dim] * 2\n",
        "    \n",
        "    # Create output array\n",
        "    output = np.zeros(output_shape, dtype=arr1.dtype)\n",
        "    \n",
        "    # Create slices for interleaving\n",
        "    slices_even = [slice(None)] * len(shape)\n",
        "    slices_odd = [slice(None)] * len(shape)\n",
        "    slices_even[dim] = slice(None, None, 2)\n",
        "    slices_odd[dim] = slice(1, None, 2)\n",
        "    \n",
        "    output[tuple(slices_even)] = arr1\n",
        "    output[tuple(slices_odd)] = arr2\n",
        "    \n",
        "    return output\n",
        "\n",
        "\n",
        "def convert_reduced_pt_to_matlab(pt_input_path, matlab_output_path):\n",
        "    \"\"\"\n",
        "    Convert reduced PyTorch dataset back to MATLAB .mat format.\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    pt_input_path : Path\n",
        "        Path to the folder containing .pt files\n",
        "    matlab_output_path : Path\n",
        "        Path to output .mat file\n",
        "    \n",
        "    Returns:\n",
        "    --------\n",
        "    dict : Information about the conversion\n",
        "    \"\"\"\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"Converting Reduced PT Dataset to MATLAB Format\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Step 1: Load Reduced PT Dataset\n",
        "    print(\"\\nStep 1: Loading Reduced PT Dataset\")\n",
        "    \n",
        "    # Load all required files\n",
        "    displacements_dataset = torch.load(pt_input_path / \"displacements_dataset.pt\", map_location='cpu')\n",
        "    reduced_indices = torch.load(pt_input_path / \"reduced_indices.pt\", map_location='cpu')\n",
        "    geometries = torch.load(pt_input_path / \"geometries_full.pt\", map_location='cpu')\n",
        "    waveforms = torch.load(pt_input_path / \"waveforms_full.pt\", map_location='cpu')\n",
        "    wavevectors = torch.load(pt_input_path / \"wavevectors_full.pt\", map_location='cpu')\n",
        "    bands_fft = torch.load(pt_input_path / \"band_fft_full.pt\", map_location='cpu')\n",
        "    design_params = torch.load(pt_input_path / \"design_params_full.pt\", map_location='cpu')\n",
        "    \n",
        "    # Convert to numpy\n",
        "    eigenvector_x_real = displacements_dataset.tensors[0].numpy()\n",
        "    eigenvector_x_imag = displacements_dataset.tensors[1].numpy()\n",
        "    eigenvector_y_real = displacements_dataset.tensors[2].numpy()\n",
        "    eigenvector_y_imag = displacements_dataset.tensors[3].numpy()\n",
        "    \n",
        "    geometries_np = geometries.numpy()\n",
        "    wavevectors_np = wavevectors.numpy()\n",
        "    design_params_np = design_params.numpy()\n",
        "    \n",
        "    # Get dimensions\n",
        "    n_designs = geometries_np.shape[0]\n",
        "    design_res = geometries_np.shape[1]\n",
        "    n_wavevectors = wavevectors_np.shape[1]\n",
        "    \n",
        "    # Determine n_bands from bands_fft\n",
        "    n_bands = bands_fft.shape[0]\n",
        "    \n",
        "    print(f\"  Loaded dataset dimensions:\")\n",
        "    print(f\"    n_designs: {n_designs}\")\n",
        "    print(f\"    design_res: {design_res}\")\n",
        "    print(f\"    n_wavevectors: {n_wavevectors}\")\n",
        "    print(f\"    n_bands: {n_bands}\")\n",
        "    print(f\"    n_reduced_samples: {len(reduced_indices)}\")\n",
        "    \n",
        "    # Step 2: Reconstruct Full EIGENVECTOR_DATA\n",
        "    print(\"\\nStep 2: Reconstructing Full EIGENVECTOR_DATA\")\n",
        "    \n",
        "    # Initialize full eigenvector arrays (fill with zeros for missing entries)\n",
        "    EIGENVECTOR_DATA_x_full = np.zeros((n_designs, n_wavevectors, n_bands, design_res, design_res), \n",
        "                                        dtype=np.complex64)\n",
        "    EIGENVECTOR_DATA_y_full = np.zeros((n_designs, n_wavevectors, n_bands, design_res, design_res), \n",
        "                                        dtype=np.complex64)\n",
        "    \n",
        "    # Place reduced eigenvectors at correct indices\n",
        "    for sample_idx, (d_idx, w_idx, b_idx) in enumerate(reduced_indices):\n",
        "        # Convert indices to int if they're tensors\n",
        "        d_idx = int(d_idx) if isinstance(d_idx, torch.Tensor) else int(d_idx)\n",
        "        w_idx = int(w_idx) if isinstance(w_idx, torch.Tensor) else int(w_idx)\n",
        "        b_idx = int(b_idx) if isinstance(b_idx, torch.Tensor) else int(b_idx)\n",
        "        \n",
        "        # Reconstruct complex eigenvectors\n",
        "        eigenvector_x = eigenvector_x_real[sample_idx] + 1j * eigenvector_x_imag[sample_idx]\n",
        "        eigenvector_y = eigenvector_y_real[sample_idx] + 1j * eigenvector_y_imag[sample_idx]\n",
        "        \n",
        "        # Place in full array\n",
        "        EIGENVECTOR_DATA_x_full[d_idx, w_idx, b_idx, :, :] = eigenvector_x\n",
        "        EIGENVECTOR_DATA_y_full[d_idx, w_idx, b_idx, :, :] = eigenvector_y\n",
        "    \n",
        "    print(f\"  Reconstructed EIGENVECTOR_DATA_x shape: {EIGENVECTOR_DATA_x_full.shape}\")\n",
        "    print(f\"  Reconstructed EIGENVECTOR_DATA_y shape: {EIGENVECTOR_DATA_y_full.shape}\")\n",
        "    \n",
        "    # Step 3: Combine x and y eigenvectors into single array\n",
        "    print(\"\\nStep 3: Combining x and y eigenvectors\")\n",
        "    \n",
        "    # Reshape to (n_designs, n_wavevectors, n_bands, 2*design_res*design_res)\n",
        "    EIGENVECTOR_DATA_x_flat = EIGENVECTOR_DATA_x_full.reshape(n_designs, n_wavevectors, n_bands, -1)\n",
        "    EIGENVECTOR_DATA_y_flat = EIGENVECTOR_DATA_y_full.reshape(n_designs, n_wavevectors, n_bands, -1)\n",
        "    \n",
        "    # Interleave x and y components\n",
        "    n_dof = 2 * design_res * design_res\n",
        "    EIGENVECTOR_DATA_combined = np.zeros((n_designs, n_wavevectors, n_bands, n_dof), dtype=np.complex64)\n",
        "    \n",
        "    # Interleave manually\n",
        "    EIGENVECTOR_DATA_combined[:, :, :, 0::2] = EIGENVECTOR_DATA_x_flat\n",
        "    EIGENVECTOR_DATA_combined[:, :, :, 1::2] = EIGENVECTOR_DATA_y_flat\n",
        "    \n",
        "    # Transpose to match MATLAB format: (n_designs, n_eig, n_wv, n_dof)\n",
        "    EIGENVECTOR_DATA = EIGENVECTOR_DATA_combined.transpose(0, 2, 1, 3)\n",
        "    \n",
        "    print(f\"  Combined EIGENVECTOR_DATA shape: {EIGENVECTOR_DATA.shape}\")\n",
        "    \n",
        "    # Step 4: Reconstruct EIGENVALUE_DATA\n",
        "    print(\"\\nStep 4: Reconstructing EIGENVALUE_DATA\")\n",
        "    \n",
        "    # Initialize with zeros (since we don't have eigenvalue data in reduced format)\n",
        "    EIGENVALUE_DATA = np.zeros((n_designs, n_bands, n_wavevectors), dtype=np.float32)\n",
        "    \n",
        "    # Fill with NaN to indicate missing data\n",
        "    EIGENVALUE_DATA[:] = np.nan\n",
        "    \n",
        "    # Transpose to match MATLAB format: (n_designs, n_eig, n_wv)\n",
        "    # Already in correct format\n",
        "    \n",
        "    print(f\"  Reconstructed EIGENVALUE_DATA shape: {EIGENVALUE_DATA.shape}\")\n",
        "    print(f\"  Note: EIGENVALUE_DATA filled with NaN (not available in reduced format)\")\n",
        "    \n",
        "    # Step 5: Reconstruct designs with all panes\n",
        "    print(\"\\nStep 5: Reconstructing designs with all panes\")\n",
        "    \n",
        "    # Original designs had 3 panes, but we only have the first pane (elastic modulus)\n",
        "    # Duplicate it for all panes\n",
        "    n_panes = 3\n",
        "    designs_full = np.zeros((n_designs, n_panes, design_res, design_res), dtype=np.float32)\n",
        "    designs_full[:, 0, :, :] = geometries_np  # First pane (elastic modulus)\n",
        "    designs_full[:, 1, :, :] = geometries_np  # Duplicate for second pane\n",
        "    designs_full[:, 2, :, :] = geometries_np  # Duplicate for third pane\n",
        "    \n",
        "    print(f\"  Reconstructed designs shape: {designs_full.shape}\")\n",
        "    \n",
        "    # Step 6: Reconstruct WAVEVECTOR_DATA\n",
        "    print(\"\\nStep 6: Reconstructing WAVEVECTOR_DATA\")\n",
        "    \n",
        "    # Transpose to match MATLAB format: (n_designs, 2, n_wv)\n",
        "    WAVEVECTOR_DATA = wavevectors_np.transpose(0, 2, 1)\n",
        "    \n",
        "    print(f\"  Reconstructed WAVEVECTOR_DATA shape: {WAVEVECTOR_DATA.shape}\")\n",
        "    \n",
        "    # Step 7: Reconstruct WAVEFORM_DATA\n",
        "    print(\"\\nStep 7: Reconstructing WAVEFORM_DATA\")\n",
        "    \n",
        "    # WAVEFORM_DATA should be (n_designs, n_wavevectors, design_res, design_res)\n",
        "    # We have waveforms for the first design, duplicate for all designs\n",
        "    WAVEFORM_DATA = np.zeros((n_designs, n_wavevectors, design_res, design_res), dtype=np.float32)\n",
        "    \n",
        "    # Use waveforms from first design (they're the same for all designs)\n",
        "    waveforms_np = waveforms.numpy()\n",
        "    for d_idx in range(n_designs):\n",
        "        WAVEFORM_DATA[d_idx, :, :, :] = waveforms_np\n",
        "    \n",
        "    print(f\"  Reconstructed WAVEFORM_DATA shape: {WAVEFORM_DATA.shape}\")\n",
        "    \n",
        "    # Step 8: Reconstruct const dictionary\n",
        "    print(\"\\nStep 8: Reconstructing const dictionary\")\n",
        "    \n",
        "    # Infer const from available data\n",
        "    # Note: N_wv grid dimensions are not available in reduced format, so we'll use a default\n",
        "    # The original had [25, 13] but we'll use [n_wavevectors, 1] as a placeholder\n",
        "    const = {\n",
        "        'N_pix': np.array([[float(design_res)]], dtype=np.float64),  # (1, 1)\n",
        "        'N_ele': np.array([[1.0]], dtype=np.float64),  # (1, 1)\n",
        "        'N_eig': np.array([[float(n_bands)]], dtype=np.float64),  # (1, 1)\n",
        "        'N_wv': np.array([[float(n_wavevectors)], [1.0]], dtype=np.float64),  # (2, 1) - placeholder\n",
        "        'a': np.array([[1.0]], dtype=np.float64),  # Default value\n",
        "        'E_max': np.array([[1.0]], dtype=np.float64),  # Default value\n",
        "        'E_min': np.array([[0.01]], dtype=np.float64),  # Default value\n",
        "        'poisson_max': np.array([[0.3]], dtype=np.float64),  # Default value\n",
        "        'poisson_min': np.array([[0.3]], dtype=np.float64),  # Default value\n",
        "        'rho_max': np.array([[1.0]], dtype=np.float64),  # Default value\n",
        "        'rho_min': np.array([[1.0]], dtype=np.float64),  # Default value\n",
        "        't': np.array([[1.0]], dtype=np.float64),  # Default value\n",
        "        'sigma_eig': np.array([[1e-2]], dtype=np.float64),  # Default value\n",
        "        'design_scale': np.array([['linear']], dtype=object),  # Default value\n",
        "        'symmetry_type': np.array([['none']], dtype=object),  # Default value\n",
        "        'eigenvector_dtype': np.array([['single']], dtype=object),  # Default value\n",
        "        'isSaveEigenvectors': np.array([[1.0]], dtype=np.float64),\n",
        "        'isSaveKandM': np.array([[0.0]], dtype=np.float64),\n",
        "        'isSaveMesh': np.array([[0.0]], dtype=np.float64),\n",
        "        'isUseGPU': np.array([[0.0]], dtype=np.float64),\n",
        "        'isUseImprovement': np.array([[1.0]], dtype=np.float64),\n",
        "        'isUseParallel': np.array([[1.0]], dtype=np.float64),\n",
        "        'isUseSecondImprovement': np.array([[0.0]], dtype=np.float64),\n",
        "        'design': np.zeros((n_panes, design_res, design_res), dtype=np.float64),  # Placeholder\n",
        "        'wavevectors': wavevectors_np[0, :, :].T  # Wavevectors from first design\n",
        "    }\n",
        "    \n",
        "    print(f\"  Reconstructed const dictionary with {len(const)} keys\")\n",
        "    \n",
        "    # Step 9: Prepare other metadata\n",
        "    print(\"\\nStep 9: Preparing metadata\")\n",
        "    \n",
        "    N_struct = np.array([[float(n_designs)]], dtype=np.float64)\n",
        "    imag_tol = np.array([[1e-6]], dtype=np.float64)  # Default value\n",
        "    rng_seed_offset = np.array([[0.0]], dtype=np.float64)  # Default value\n",
        "    \n",
        "    # Step 10: Save as MATLAB v7.3 format\n",
        "    print(\"\\nStep 10: Saving as MATLAB v7.3 format\")\n",
        "    \n",
        "    # Prepare dataset dictionary\n",
        "    dataset = {\n",
        "        'WAVEVECTOR_DATA': WAVEVECTOR_DATA.astype(np.float32),\n",
        "        'EIGENVALUE_DATA': EIGENVALUE_DATA.astype(np.float32),\n",
        "        'EIGENVECTOR_DATA': EIGENVECTOR_DATA.astype(np.complex64),\n",
        "        'designs': designs_full.astype(np.float32),\n",
        "        'design_params': design_params_np.astype(np.float64),\n",
        "        'N_struct': N_struct.astype(np.float64),\n",
        "        'imag_tol': imag_tol.astype(np.float64),\n",
        "        'rng_seed_offset': rng_seed_offset.astype(np.float64),\n",
        "    }\n",
        "    \n",
        "    # Save const as a struct\n",
        "    with h5py.File(matlab_output_path, 'w') as f:\n",
        "        # Save regular arrays\n",
        "        for key, value in dataset.items():\n",
        "            if key == 'EIGENVECTOR_DATA':\n",
        "                # Save complex array as structured array (compound dtype) - MATLAB v7.3 format\n",
        "                # Convert to float32 (single precision) to match original MATLAB format\n",
        "                EIGENVECTOR_DATA_real = value.real.astype(np.float32)\n",
        "                EIGENVECTOR_DATA_imag = value.imag.astype(np.float32)\n",
        "                \n",
        "                # Create structured array with compound dtype (matches MATLAB format)\n",
        "                structured_dtype = np.dtype([('real', np.float32), ('imag', np.float32)])\n",
        "                EIGENVECTOR_DATA_structured = np.empty(value.shape, dtype=structured_dtype)\n",
        "                EIGENVECTOR_DATA_structured['real'] = EIGENVECTOR_DATA_real\n",
        "                EIGENVECTOR_DATA_structured['imag'] = EIGENVECTOR_DATA_imag\n",
        "                \n",
        "                # Create dataset with structured dtype (compound datatype)\n",
        "                dset = f.create_dataset(\n",
        "                    'EIGENVECTOR_DATA',\n",
        "                    data=EIGENVECTOR_DATA_structured,\n",
        "                    dtype=structured_dtype\n",
        "                )\n",
        "                # Add MATLAB_class attribute to indicate it's a single-precision complex array\n",
        "                dset.attrs['MATLAB_class'] = np.bytes_(b'single')\n",
        "            else:\n",
        "                f.create_dataset(key, data=value)\n",
        "        \n",
        "        # Save const as a struct group\n",
        "        const_grp = f.create_group('const')\n",
        "        for key, value in const.items():\n",
        "            if isinstance(value, np.ndarray):\n",
        "                if value.dtype == object:\n",
        "                    # Handle string arrays\n",
        "                    dt = h5py.special_dtype(vlen=str)\n",
        "                    dset = const_grp.create_dataset(key, value.shape, dtype=dt)\n",
        "                    dset[:] = value.astype(str)\n",
        "                else:\n",
        "                    const_grp.create_dataset(key, data=value)\n",
        "            else:\n",
        "                const_grp.attrs[key] = value\n",
        "    \n",
        "    elapsed_time = time.time() - start_time\n",
        "    file_size = matlab_output_path.stat().st_size / (1024 * 1024)\n",
        "    \n",
        "    print(f\"  Saved to: {matlab_output_path}\")\n",
        "    print(f\"  File size: {file_size:.2f} MB\")\n",
        "    print(f\"  Conversion completed in {elapsed_time:.2f} seconds\")\n",
        "    \n",
        "    return {\n",
        "        'output_path': matlab_output_path,\n",
        "        'file_size_mb': file_size,\n",
        "        'elapsed_time': elapsed_time,\n",
        "        'n_designs': n_designs,\n",
        "        'n_wavevectors': n_wavevectors,\n",
        "        'n_bands': n_bands\n",
        "    }\n",
        "\n",
        "print(\"Inverse conversion function defined.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run Conversion\n",
        "\n",
        "Execute the conversion function:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the conversion\n",
        "result = convert_reduced_pt_to_matlab(pt_input_path, matlab_output_path)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Conversion Summary\")\n",
        "print(\"=\" * 80)\n",
        "print(f\"Output file: {result['output_path']}\")\n",
        "print(f\"File size: {result['file_size_mb']:.2f} MB\")\n",
        "print(f\"Conversion time: {result['elapsed_time']:.2f} seconds\")\n",
        "print(f\"n_designs: {result['n_designs']}\")\n",
        "print(f\"n_wavevectors: {result['n_wavevectors']}\")\n",
        "print(f\"n_bands: {result['n_bands']}\")\n",
        "print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Verification\n",
        "\n",
        "Verify that the reconstructed MATLAB file can be loaded and has the correct structure:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Verify the reconstructed file\n",
        "print(\"=\" * 80)\n",
        "print(\"Verifying Reconstructed MATLAB File\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Load the reconstructed file\n",
        "import h5py\n",
        "\n",
        "with h5py.File(matlab_output_path, 'r') as f:\n",
        "    print(\"\\nKeys in reconstructed file:\")\n",
        "    print(list(f.keys()))\n",
        "    \n",
        "    print(\"\\nShapes of main arrays:\")\n",
        "    if 'EIGENVECTOR_DATA' in f:\n",
        "        ev_shape = f['EIGENVECTOR_DATA']['real'].shape\n",
        "        print(f\"  EIGENVECTOR_DATA: {ev_shape}\")\n",
        "    \n",
        "    if 'EIGENVALUE_DATA' in f:\n",
        "        eigval_shape = f['EIGENVALUE_DATA'].shape\n",
        "        print(f\"  EIGENVALUE_DATA: {eigval_shape}\")\n",
        "    \n",
        "    if 'WAVEVECTOR_DATA' in f:\n",
        "        wv_shape = f['WAVEVECTOR_DATA'].shape\n",
        "        print(f\"  WAVEVECTOR_DATA: {wv_shape}\")\n",
        "    \n",
        "    if 'designs' in f:\n",
        "        designs_shape = f['designs'].shape\n",
        "        print(f\"  designs: {designs_shape}\")\n",
        "    \n",
        "    if 'const' in f:\n",
        "        print(f\"\\nconst keys: {list(f['const'].keys())}\")\n",
        "\n",
        "# Also try loading with NO_utils to verify compatibility\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"Testing compatibility with NO_utils.extract_data()\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "try:\n",
        "    # Create a temporary directory with the reconstructed file\n",
        "    import tempfile\n",
        "    import shutil\n",
        "    \n",
        "    temp_dir = tempfile.mkdtemp(prefix=\"verify_reconstructed_\")\n",
        "    temp_mat_path = Path(temp_dir) / matlab_output_path.name\n",
        "    \n",
        "    # Copy the reconstructed file to temp directory\n",
        "    shutil.copy2(matlab_output_path, temp_mat_path)\n",
        "    \n",
        "    # Try to extract data using NO_utils\n",
        "    (designs, design_params, n_designs, n_panes, design_res,\n",
        "     WAVEVECTOR_DATA, WAVEFORM_DATA, n_dim, n_wavevectors,\n",
        "     EIGENVALUE_DATA, n_bands, EIGENVECTOR_DATA_x,\n",
        "     EIGENVECTOR_DATA_y, const, N_struct,\n",
        "     imag_tol, rng_seed_offset) = NO_utils.extract_data(temp_dir)\n",
        "    \n",
        "    print(\"\\n✓ Successfully loaded with NO_utils.extract_data()!\")\n",
        "    print(f\"  n_designs: {n_designs}\")\n",
        "    print(f\"  n_panes: {n_panes}\")\n",
        "    print(f\"  design_res: {design_res}\")\n",
        "    print(f\"  n_wavevectors: {n_wavevectors}\")\n",
        "    print(f\"  n_bands: {n_bands}\")\n",
        "    print(f\"  EIGENVECTOR_DATA_x shape: {EIGENVECTOR_DATA_x.shape}\")\n",
        "    print(f\"  EIGENVECTOR_DATA_y shape: {EIGENVECTOR_DATA_y.shape}\")\n",
        "    \n",
        "    # Clean up\n",
        "    shutil.rmtree(temp_dir, ignore_errors=True)\n",
        "    \n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"✓ Verification successful! The reconstructed file is compatible.\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\n✗ Error during verification: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()\n",
        "    # Clean up\n",
        "    shutil.rmtree(temp_dir, ignore_errors=True)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
