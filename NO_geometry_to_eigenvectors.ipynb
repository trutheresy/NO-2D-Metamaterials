{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:11:33.329607400Z",
     "start_time": "2024-03-25T08:11:23.338736700Z"
    }
   },
   "outputs": [],
   "source": [
    "# Import modules for building a neural operator model\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Import specialized neural operator model tools\n",
    "from neuralop.models import FNO, TFNO\n",
    "from neuralop import Trainer\n",
    "from neuralop.datasets import load_darcy_flow_small\n",
    "from neuralop.utils import count_model_params\n",
    "from neuralop.datasets import data_transforms\n",
    "from neuralop import LpLoss, H1Loss\n",
    "\n",
    "# For creating datasets and data loaders for training and evaluation\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, random_split\n",
    "\n",
    "# Optional: torchvision for augmentations and transformations (if working with image-like data)\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# For plotting and visualization\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Optional: Use tqdm for progress bars during training and evaluation\n",
    "from tqdm import tqdm\n",
    "\n",
    "# For handling file paths and directories\n",
    "import os\n",
    "import sys\n",
    "import h5py\n",
    "\n",
    "# Optional: If your model or data processing requires specific numerical operations (e.g., FFT)\n",
    "from torch.fft import fft, ifft\n",
    "\n",
    "# Optional: If you are working with graph data or architectures\n",
    "# import torch_geometric\n",
    "\n",
    "# If you need automatic differentiation for custom operations or gradients\n",
    "from torch.autograd import Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Device: cuda\n",
      "Using PyTorch version: 2.1.0\n"
     ]
    }
   ],
   "source": [
    "#Set the device for the neural operator model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using Device:', device)\n",
    "print(\"Using PyTorch version:\", torch.__version__)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:11:33.377935500Z",
     "start_time": "2024-03-25T08:11:33.331607500Z"
    }
   },
   "id": "ccbd700ab9b52f1f"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OUTPUT\\preliminary_datasets\\DATA N_pix32x32 N_ele1x1 N_wv25x13 N_disp100 N_eig6 offset0 01-Mar-2024 19-13-23.mat\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\zhang\\AppData\\Local\\Temp\\ipykernel_14568\\3278998178.py:21: UserWarning: ComplexHalf support is experimental and many operators don't support it yet. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\aten\\src\\ATen\\EmptyTensor.cpp:32.)\n",
      "  EIGENVECTOR_DATA_tensor = torch.tensor(EIGENVECTOR_DATA, dtype=torch.complex32)\n"
     ]
    }
   ],
   "source": [
    "#Load the data for the neural operator model\n",
    "datafolder_name = [\"OUTPUT\",\"preliminary_datasets\"]\n",
    "datafile_name = \"DATA N_pix32x32 N_ele1x1 N_wv25x13 N_disp100 N_eig6 offset0 01-Mar-2024 19-13-23.mat\"\n",
    "data_path = os.path.join(*datafolder_name, datafile_name)\n",
    "print(data_path)\n",
    "\n",
    "# Load the .mat file using h5py\n",
    "with h5py.File(data_path, 'r') as file:\n",
    "    # print(file['EIGENVECTOR_DATA'].dtype.names)\n",
    "    # print(file['EIGENVALUE_DATA'].dtype.names)\n",
    "    # print(file['WAVEVECTOR_DATA'].dtype.names)\n",
    "    # Load the data arrays\n",
    "    EIGENVALUE_DATA = np.array(file['EIGENVALUE_DATA'], dtype=np.float16)\n",
    "    EIGENVECTOR_DATA_real = np.array(file['EIGENVECTOR_DATA']['real'], dtype=np.float16)\n",
    "    EIGENVECTOR_DATA_imag = np.array(file['EIGENVECTOR_DATA']['imag'], dtype=np.float16)\n",
    "    EIGENVECTOR_DATA = EIGENVECTOR_DATA_real + 1j * EIGENVECTOR_DATA_imag\n",
    "    WAVEVECTOR_DATA = np.array(file['WAVEVECTOR_DATA'], dtype=np.float16)\n",
    "\n",
    "    # Convert to PyTorch tensors\n",
    "    EIGENVALUE_DATA_tensor = torch.tensor(EIGENVALUE_DATA, dtype=torch.float16)\n",
    "    EIGENVECTOR_DATA_tensor = torch.tensor(EIGENVECTOR_DATA, dtype=torch.complex32)\n",
    "    WAVEVECTOR_DATA_tensor = torch.tensor(WAVEVECTOR_DATA, dtype=torch.float16)\n",
    "\n",
    "    # Unpack the 'const' struct\n",
    "    # This assumes 'const' contains datasets directly. If it contains groups, you'll need to adjust the code\n",
    "    const = {key: np.array(file['const'][key]) for key in file['const']}\n",
    "\n",
    "    # Assign numbers to variables\n",
    "    N_struct = np.array(file['N_struct'])  # Adjust indexing if necessary\n",
    "    design_params = np.array(file['design_params'])\n",
    "    designs = np.array(file['designs'])\n",
    "    imag_tol = np.array(file['imag_tol'])\n",
    "    rng_seed_offset = np.array(file['rng_seed_offset'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:18:17.469354300Z",
     "start_time": "2024-03-25T08:17:16.452722800Z"
    }
   },
   "id": "f1f917ca2deb400e"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EIGENVALUE_DATA shape: torch.Size([100, 6, 325])\n",
      "EIGENVECTOR_DATA shape: torch.Size([100, 6, 325, 2048])\n",
      "WAVEVECTOR_DATA shape: torch.Size([100, 2, 325])\n",
      "N_struct: [[100.]]\n",
      "design_params: [[3707764736          2          1          1          2          2]]\n",
      "designs: [[[[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   ...\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]\n",
      "   [0.         0.         0.         ... 0.         0.\n",
      "    0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.52016533 0.48535184 0.46221303 ... 0.46221303 0.48535184\n",
      "    0.52016533]\n",
      "   [0.48535184 0.45152392 0.45100394 ... 0.45100394 0.45152392\n",
      "    0.48535184]\n",
      "   [0.46221303 0.45100394 0.42990036 ... 0.42990036 0.45100394\n",
      "    0.46221303]\n",
      "   ...\n",
      "   [0.46221303 0.45100394 0.42990036 ... 0.42990036 0.45100394\n",
      "    0.46221303]\n",
      "   [0.48535184 0.45152392 0.45100394 ... 0.45100394 0.45152392\n",
      "    0.48535184]\n",
      "   [0.52016533 0.48535184 0.46221303 ... 0.46221303 0.48535184\n",
      "    0.52016533]]\n",
      "\n",
      "  [[0.52016533 0.48535184 0.46221303 ... 0.46221303 0.48535184\n",
      "    0.52016533]\n",
      "   [0.48535184 0.45152392 0.45100394 ... 0.45100394 0.45152392\n",
      "    0.48535184]\n",
      "   [0.46221303 0.45100394 0.42990036 ... 0.42990036 0.45100394\n",
      "    0.46221303]\n",
      "   ...\n",
      "   [0.46221303 0.45100394 0.42990036 ... 0.42990036 0.45100394\n",
      "    0.46221303]\n",
      "   [0.48535184 0.45152392 0.45100394 ... 0.45100394 0.45152392\n",
      "    0.48535184]\n",
      "   [0.52016533 0.48535184 0.46221303 ... 0.46221303 0.48535184\n",
      "    0.52016533]]\n",
      "\n",
      "  [[0.52016533 0.48535184 0.46221303 ... 0.46221303 0.48535184\n",
      "    0.52016533]\n",
      "   [0.48535184 0.45152392 0.45100394 ... 0.45100394 0.45152392\n",
      "    0.48535184]\n",
      "   [0.46221303 0.45100394 0.42990036 ... 0.42990036 0.45100394\n",
      "    0.46221303]\n",
      "   ...\n",
      "   [0.46221303 0.45100394 0.42990036 ... 0.42990036 0.45100394\n",
      "    0.46221303]\n",
      "   [0.48535184 0.45152392 0.45100394 ... 0.45100394 0.45152392\n",
      "    0.48535184]\n",
      "   [0.52016533 0.48535184 0.46221303 ... 0.46221303 0.48535184\n",
      "    0.52016533]]]\n",
      "\n",
      "\n",
      " [[[0.51567435 0.53466766 0.59908178 ... 0.59908178 0.53466766\n",
      "    0.51567435]\n",
      "   [0.53466766 0.55240559 0.61659554 ... 0.61659554 0.55240559\n",
      "    0.53466766]\n",
      "   [0.59908178 0.61659554 0.69871271 ... 0.69871271 0.61659554\n",
      "    0.59908178]\n",
      "   ...\n",
      "   [0.59908178 0.61659554 0.69871271 ... 0.69871271 0.61659554\n",
      "    0.59908178]\n",
      "   [0.53466766 0.55240559 0.61659554 ... 0.61659554 0.55240559\n",
      "    0.53466766]\n",
      "   [0.51567435 0.53466766 0.59908178 ... 0.59908178 0.53466766\n",
      "    0.51567435]]\n",
      "\n",
      "  [[0.51567435 0.53466766 0.59908178 ... 0.59908178 0.53466766\n",
      "    0.51567435]\n",
      "   [0.53466766 0.55240559 0.61659554 ... 0.61659554 0.55240559\n",
      "    0.53466766]\n",
      "   [0.59908178 0.61659554 0.69871271 ... 0.69871271 0.61659554\n",
      "    0.59908178]\n",
      "   ...\n",
      "   [0.59908178 0.61659554 0.69871271 ... 0.69871271 0.61659554\n",
      "    0.59908178]\n",
      "   [0.53466766 0.55240559 0.61659554 ... 0.61659554 0.55240559\n",
      "    0.53466766]\n",
      "   [0.51567435 0.53466766 0.59908178 ... 0.59908178 0.53466766\n",
      "    0.51567435]]\n",
      "\n",
      "  [[0.51567435 0.53466766 0.59908178 ... 0.59908178 0.53466766\n",
      "    0.51567435]\n",
      "   [0.53466766 0.55240559 0.61659554 ... 0.61659554 0.55240559\n",
      "    0.53466766]\n",
      "   [0.59908178 0.61659554 0.69871271 ... 0.69871271 0.61659554\n",
      "    0.59908178]\n",
      "   ...\n",
      "   [0.59908178 0.61659554 0.69871271 ... 0.69871271 0.61659554\n",
      "    0.59908178]\n",
      "   [0.53466766 0.55240559 0.61659554 ... 0.61659554 0.55240559\n",
      "    0.53466766]\n",
      "   [0.51567435 0.53466766 0.59908178 ... 0.59908178 0.53466766\n",
      "    0.51567435]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]]\n",
      "\n",
      "  [[1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]]\n",
      "\n",
      "  [[1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   ...\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]\n",
      "   [1.         1.         1.         ... 1.         1.\n",
      "    1.        ]]]\n",
      "\n",
      "\n",
      " [[[0.44007857 0.41052704 0.45642916 ... 0.45642916 0.41052704\n",
      "    0.44007857]\n",
      "   [0.41052704 0.38459481 0.42507118 ... 0.42507118 0.38459481\n",
      "    0.41052704]\n",
      "   [0.45642916 0.42507118 0.41776634 ... 0.41776634 0.42507118\n",
      "    0.45642916]\n",
      "   ...\n",
      "   [0.45642916 0.42507118 0.41776634 ... 0.41776634 0.42507118\n",
      "    0.45642916]\n",
      "   [0.41052704 0.38459481 0.42507118 ... 0.42507118 0.38459481\n",
      "    0.41052704]\n",
      "   [0.44007857 0.41052704 0.45642916 ... 0.45642916 0.41052704\n",
      "    0.44007857]]\n",
      "\n",
      "  [[0.44007857 0.41052704 0.45642916 ... 0.45642916 0.41052704\n",
      "    0.44007857]\n",
      "   [0.41052704 0.38459481 0.42507118 ... 0.42507118 0.38459481\n",
      "    0.41052704]\n",
      "   [0.45642916 0.42507118 0.41776634 ... 0.41776634 0.42507118\n",
      "    0.45642916]\n",
      "   ...\n",
      "   [0.45642916 0.42507118 0.41776634 ... 0.41776634 0.42507118\n",
      "    0.45642916]\n",
      "   [0.41052704 0.38459481 0.42507118 ... 0.42507118 0.38459481\n",
      "    0.41052704]\n",
      "   [0.44007857 0.41052704 0.45642916 ... 0.45642916 0.41052704\n",
      "    0.44007857]]\n",
      "\n",
      "  [[0.44007857 0.41052704 0.45642916 ... 0.45642916 0.41052704\n",
      "    0.44007857]\n",
      "   [0.41052704 0.38459481 0.42507118 ... 0.42507118 0.38459481\n",
      "    0.41052704]\n",
      "   [0.45642916 0.42507118 0.41776634 ... 0.41776634 0.42507118\n",
      "    0.45642916]\n",
      "   ...\n",
      "   [0.45642916 0.42507118 0.41776634 ... 0.41776634 0.42507118\n",
      "    0.45642916]\n",
      "   [0.41052704 0.38459481 0.42507118 ... 0.42507118 0.38459481\n",
      "    0.41052704]\n",
      "   [0.44007857 0.41052704 0.45642916 ... 0.45642916 0.41052704\n",
      "    0.44007857]]]\n",
      "\n",
      "\n",
      " [[[1.         0.90731304 0.73398838 ... 0.73398838 0.90731304\n",
      "    1.        ]\n",
      "   [0.90731304 0.8206991  0.68239211 ... 0.68239211 0.8206991\n",
      "    0.90731304]\n",
      "   [0.73398838 0.68239211 0.61668125 ... 0.61668125 0.68239211\n",
      "    0.73398838]\n",
      "   ...\n",
      "   [0.73398838 0.68239211 0.61668125 ... 0.61668125 0.68239211\n",
      "    0.73398838]\n",
      "   [0.90731304 0.8206991  0.68239211 ... 0.68239211 0.8206991\n",
      "    0.90731304]\n",
      "   [1.         0.90731304 0.73398838 ... 0.73398838 0.90731304\n",
      "    1.        ]]\n",
      "\n",
      "  [[1.         0.90731304 0.73398838 ... 0.73398838 0.90731304\n",
      "    1.        ]\n",
      "   [0.90731304 0.8206991  0.68239211 ... 0.68239211 0.8206991\n",
      "    0.90731304]\n",
      "   [0.73398838 0.68239211 0.61668125 ... 0.61668125 0.68239211\n",
      "    0.73398838]\n",
      "   ...\n",
      "   [0.73398838 0.68239211 0.61668125 ... 0.61668125 0.68239211\n",
      "    0.73398838]\n",
      "   [0.90731304 0.8206991  0.68239211 ... 0.68239211 0.8206991\n",
      "    0.90731304]\n",
      "   [1.         0.90731304 0.73398838 ... 0.73398838 0.90731304\n",
      "    1.        ]]\n",
      "\n",
      "  [[1.         0.90731304 0.73398838 ... 0.73398838 0.90731304\n",
      "    1.        ]\n",
      "   [0.90731304 0.8206991  0.68239211 ... 0.68239211 0.8206991\n",
      "    0.90731304]\n",
      "   [0.73398838 0.68239211 0.61668125 ... 0.61668125 0.68239211\n",
      "    0.73398838]\n",
      "   ...\n",
      "   [0.73398838 0.68239211 0.61668125 ... 0.61668125 0.68239211\n",
      "    0.73398838]\n",
      "   [0.90731304 0.8206991  0.68239211 ... 0.68239211 0.8206991\n",
      "    0.90731304]\n",
      "   [1.         0.90731304 0.73398838 ... 0.73398838 0.90731304\n",
      "    1.        ]]]]\n",
      "imag_tol: [[0.001]]\n"
     ]
    }
   ],
   "source": [
    "# Print shapes or values to verify\n",
    "print(\"EIGENVALUE_DATA shape:\", EIGENVALUE_DATA_tensor.shape)\n",
    "print(\"EIGENVECTOR_DATA shape:\", EIGENVECTOR_DATA_tensor.shape) #Complex valued, 32x32 nodes, 2 DoF per node, 100 structs, 6 bands\n",
    "print(\"WAVEVECTOR_DATA shape:\", WAVEVECTOR_DATA_tensor.shape)\n",
    "#print(\"const contents:\", const)\n",
    "print(\"N_struct:\", N_struct)\n",
    "print(\"design_params:\", design_params)\n",
    "print(\"designs:\", designs)\n",
    "print(\"imag_tol:\", imag_tol)\n",
    "#print(\"rng_seed_offset:\", rng_seed_offset)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:19:31.446483300Z",
     "start_time": "2024-03-25T08:19:31.409910400Z"
    }
   },
   "id": "b66eb3117bfd0f5d"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "def plot_histograms(array_slice):\n",
    "    \"\"\"\n",
    "    Plots histograms for the input array slice.\n",
    "    If the array slice contains real numbers, plots one histogram.\n",
    "    If the array slice contains complex numbers, plots two histograms side by side,\n",
    "    one for the real parts and one for the imaginary parts.\n",
    "    \"\"\"\n",
    "    # Check if the array slice contains complex numbers\n",
    "    if np.iscomplexobj(array_slice):\n",
    "        # Prepare the plot area with two subplots\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "        # Plot histogram of real parts\n",
    "        axs[0].hist(array_slice.real, bins=100, color='skyblue', edgecolor='black')\n",
    "        axs[0].set_title('Histogram of Real Parts')\n",
    "\n",
    "        # Plot histogram of imaginary parts\n",
    "        axs[1].hist(array_slice.imag, bins=100, color='salmon', edgecolor='black')\n",
    "        axs[1].set_title('Histogram of Imaginary Parts')\n",
    "\n",
    "        plt.suptitle('Histograms of Complex Array Slice')\n",
    "    else:\n",
    "        # Plot a single histogram for real-valued array slice\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.hist(array_slice, bins=30, color='skyblue', edgecolor='black')\n",
    "        plt.title('Histogram of Real Array Slice')\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:19:34.651497100Z",
     "start_time": "2024-03-25T08:19:34.637922200Z"
    }
   },
   "id": "db6575ea7fe2d3ea"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1200x400 with 2 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "struct = 20\n",
    "band = 3\n",
    "wavevector = 0\n",
    "node = 0\n",
    "plot_histograms(EIGENVECTOR_DATA[struct, band, wavevector, :])\n",
    "#plot_histograms(WAVEVECTOR_DATA[struct, 0, :])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:21:07.945085700Z",
     "start_time": "2024-03-25T08:21:07.630207400Z"
    }
   },
   "id": "d75a9bce039ce50b"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "class NormalizeOutput:\n",
    "    def __init__(self, mean=None, std=None):\n",
    "        self.mean = mean\n",
    "        self.std = std\n",
    "\n",
    "    def fit(self, outputs):\n",
    "        \"\"\"Calculate mean and std deviation from the dataset if not provided.\"\"\"\n",
    "        if self.mean is None or self.std is None:\n",
    "            self.mean = outputs.mean(axis=0)\n",
    "            self.std = outputs.std(axis=0)\n",
    "\n",
    "    def transform(self, outputs):\n",
    "        \"\"\"Normalize the outputs.\"\"\"\n",
    "        return (outputs - self.mean) / self.std\n",
    "\n",
    "    def inverse_transform(self, normalized_outputs):\n",
    "        \"\"\"Reverse the normalization to get the original scale of outputs.\"\"\"\n",
    "        return normalized_outputs * self.std + self.mean\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:25:53.974939600Z",
     "start_time": "2024-03-25T08:25:53.961820400Z"
    }
   },
   "id": "a07613f3b431a93b"
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "designs shape: (100, 3, 32, 32)\n",
      "EIGENVECTOR_DATA slice shape: (100, 2048)\n",
      "x_train shape: torch.Size([100, 3, 32, 32])\n",
      "y_train shape: torch.Size([100, 1, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Use designs as x_train and EIGENVECTOR_DATA as y_train\n",
    "print(\"designs shape:\", designs.shape)\n",
    "print(\"EIGENVECTOR_DATA slice shape:\", EIGENVECTOR_DATA[:,0,0,:].shape)\n",
    "x_train = torch.tensor(designs, dtype=torch.float32)\n",
    "y_train = EIGENVECTOR_DATA_tensor[:,0,0,:].reshape(100, 2, 32,32)\n",
    "y_train = y_train[:,0,:,:]\n",
    "y_train = y_train.reshape(100, 1, 32, 32)\n",
    "# y_train_real = y_train.real\n",
    "# y_train_imag = y_train.imag\n",
    "# y_train = torch.stack((y_train_real, y_train_imag), dim=1).reshape(100, 4, 32, 32)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:59:33.865491300Z",
     "start_time": "2024-03-25T08:59:33.834482700Z"
    }
   },
   "id": "e3f631c570c6d56d"
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1.) tensor(0.)\n",
      "tensor(0.2500, dtype=torch.float16) tensor(0., dtype=torch.float16)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Normalize the outputs\n",
    "# normalizer = NormalizeOutput()\n",
    "# normalizer.fit(y_train.numpy())\n",
    "# normalized_outputs = normalizer.transform(y_train.numpy())\n",
    "# y_train = torch.tensor(normalized_outputs, dtype=torch.float32)\n",
    "# print(normalizer.mean, normalizer.std)\n",
    "\n",
    "dataset = torch.utils.data.TensorDataset(x_train, y_train)\n",
    "print(torch.max(x_train), torch.min(x_train))\n",
    "print(torch.max(torch.abs(y_train)), torch.min(torch.abs(y_train)))\n",
    "#print(len(dataset))\n",
    "# Define the sizes of train and test datasets\n",
    "train_size = int(0.8 * len(dataset))  # 80% for training\n",
    "test_size = len(dataset) - train_size  # Remaining 20% for testing\n",
    "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=10, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:59:36.348119400Z",
     "start_time": "2024-03-25T08:59:36.320995500Z"
    }
   },
   "id": "a81396b025626683"
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [],
   "source": [
    "class DataLoaderWrapper:\n",
    "    def __init__(self, dataloader):\n",
    "        self.dataloader = dataloader\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Iterate over the original DataLoader\n",
    "        for batch in self.dataloader:\n",
    "            inputs, outputs = batch  # Unpack the batch\n",
    "            # Yield a dictionary with 'inputs' and 'outputs' keys\n",
    "            yield {'x': inputs, 'y': outputs}\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the length of the original DataLoader\n",
    "        return len(self.dataloader)\n",
    "\n",
    "    def items(self):\n",
    "        # Return a list of tuples containing the key-value pairs\n",
    "        return [('x', self.dataloader.dataset.inputs), ('y', self.dataloader.dataset.outputs)]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:05:24.745474400Z",
     "start_time": "2024-03-25T09:05:24.715467200Z"
    }
   },
   "id": "e64bec2ed96e5ece"
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "outputs": [],
   "source": [
    "train_loader_wrapped = DataLoaderWrapper(train_loader)\n",
    "test_loader_wrapped = DataLoaderWrapper(test_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:05:25.954876100Z",
     "start_time": "2024-03-25T09:05:25.926848900Z"
    }
   },
   "id": "7d5b1708897c353b"
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Operator model has 1212337 parameters.\n"
     ]
    }
   ],
   "source": [
    "NO_model = TFNO(n_modes=(16, 16), in_channels=3, out_channels=1, hidden_channels=32, projection_channels=4)\n",
    "NO_params = count_model_params(NO_model)\n",
    "print(f'Neural Operator model has {NO_params} parameters.')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:19:18.905949Z",
     "start_time": "2024-03-25T09:19:18.867312900Z"
    }
   },
   "id": "7f5f75940a27af33"
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(NO_model.parameters(),\n",
    "                             lr=1e-2,\n",
    "                             weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
    "#optimizer = torch.optim.AdamW(NO_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "#scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5, verbose=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:28:26.294815500Z",
     "start_time": "2024-03-25T09:28:26.257807700Z"
    }
   },
   "id": "c68aa5fa0f6629e8"
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "outputs": [],
   "source": [
    "# Make sure your model is on the correct device\n",
    "NO_model.to(device)\n",
    "\n",
    "l2loss = LpLoss(d=2, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "\n",
    "train_loss = h1loss\n",
    "eval_losses={'h1': h1loss, 'l2': l2loss}\n",
    "\n",
    "# Prepare dictionaries to hold training and validation losses\n",
    "train_losses = []\n",
    "valid_losses = {'h1': [], 'l2': []}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:28:27.535282200Z",
     "start_time": "2024-03-25T09:28:27.510694200Z"
    }
   },
   "id": "3f5d22372444c11e"
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Batch 1/4, Loss: 96.8008041381836\n",
      "Epoch 1/200 completed, Average Loss: 575.7813749313354\n",
      "Validation Loss after Epoch 1/200: 21.15431785583496\n",
      "\n",
      "Epoch 2/200, Batch 1/4, Loss: 43.56922149658203\n",
      "Epoch 2/200 completed, Average Loss: 53.39036273956299\n",
      "Validation Loss after Epoch 2/200: 12.02341365814209\n",
      "\n",
      "Epoch 3/200, Batch 1/4, Loss: 23.356094360351562\n",
      "Epoch 3/200 completed, Average Loss: 24.198159217834473\n",
      "Validation Loss after Epoch 3/200: 13.744132041931152\n",
      "\n",
      "Epoch 4/200, Batch 1/4, Loss: 27.9241886138916\n",
      "Epoch 4/200 completed, Average Loss: 32.71749210357666\n",
      "Validation Loss after Epoch 4/200: 12.539332866668701\n",
      "\n",
      "Epoch 5/200, Batch 1/4, Loss: 24.458972930908203\n",
      "Epoch 5/200 completed, Average Loss: 23.429738998413086\n",
      "Validation Loss after Epoch 5/200: 11.023078441619873\n",
      "\n",
      "Epoch 6/200, Batch 1/4, Loss: 23.421674728393555\n",
      "Epoch 6/200 completed, Average Loss: 22.76424217224121\n",
      "Validation Loss after Epoch 6/200: 11.161680698394775\n",
      "\n",
      "Epoch 7/200, Batch 1/4, Loss: 23.53661346435547\n",
      "Epoch 7/200 completed, Average Loss: 21.448421478271484\n",
      "Validation Loss after Epoch 7/200: 9.973391056060791\n",
      "\n",
      "Epoch 8/200, Batch 1/4, Loss: 19.95762825012207\n",
      "Epoch 8/200 completed, Average Loss: 20.17875385284424\n",
      "Validation Loss after Epoch 8/200: 9.96623706817627\n",
      "\n",
      "Epoch 9/200, Batch 1/4, Loss: 19.732389450073242\n",
      "Epoch 9/200 completed, Average Loss: 20.020573139190674\n",
      "Validation Loss after Epoch 9/200: 9.983062744140625\n",
      "\n",
      "Epoch 10/200, Batch 1/4, Loss: 20.096040725708008\n",
      "Epoch 10/200 completed, Average Loss: 20.219762325286865\n",
      "Validation Loss after Epoch 10/200: 9.976857662200928\n",
      "\n",
      "Epoch 11/200, Batch 1/4, Loss: 19.982925415039062\n",
      "Epoch 11/200 completed, Average Loss: 20.136375427246094\n",
      "Validation Loss after Epoch 11/200: 10.029025554656982\n",
      "\n",
      "Epoch 12/200, Batch 1/4, Loss: 20.09741973876953\n",
      "Epoch 12/200 completed, Average Loss: 19.917870044708252\n",
      "Validation Loss after Epoch 12/200: 9.999821186065674\n",
      "\n",
      "Epoch 13/200, Batch 1/4, Loss: 20.08086395263672\n",
      "Epoch 13/200 completed, Average Loss: 19.970934867858887\n",
      "Validation Loss after Epoch 13/200: 9.955909729003906\n",
      "\n",
      "Epoch 14/200, Batch 1/4, Loss: 19.93635368347168\n",
      "Epoch 14/200 completed, Average Loss: 19.968505382537842\n",
      "Validation Loss after Epoch 14/200: 9.97802734375\n",
      "\n",
      "Epoch 15/200, Batch 1/4, Loss: 19.62665367126465\n",
      "Epoch 15/200 completed, Average Loss: 19.875542163848877\n",
      "Validation Loss after Epoch 15/200: 9.966115951538086\n",
      "\n",
      "Epoch 16/200, Batch 1/4, Loss: 19.852436065673828\n",
      "Epoch 16/200 completed, Average Loss: 20.05453062057495\n",
      "Validation Loss after Epoch 16/200: 9.972593784332275\n",
      "\n",
      "Epoch 17/200, Batch 1/4, Loss: 20.107826232910156\n",
      "Epoch 17/200 completed, Average Loss: 20.018260955810547\n",
      "Validation Loss after Epoch 17/200: 10.029637813568115\n",
      "\n",
      "Epoch 18/200, Batch 1/4, Loss: 20.27873992919922\n",
      "Epoch 18/200 completed, Average Loss: 19.973529815673828\n",
      "Validation Loss after Epoch 18/200: 9.953325748443604\n",
      "\n",
      "Epoch 19/200, Batch 1/4, Loss: 19.946884155273438\n",
      "Epoch 19/200 completed, Average Loss: 19.909849166870117\n",
      "Validation Loss after Epoch 19/200: 9.95146894454956\n",
      "\n",
      "Epoch 20/200, Batch 1/4, Loss: 19.798511505126953\n",
      "Epoch 20/200 completed, Average Loss: 19.896305561065674\n",
      "Validation Loss after Epoch 20/200: 9.950454235076904\n",
      "\n",
      "Epoch 21/200, Batch 1/4, Loss: 19.76340103149414\n",
      "Epoch 21/200 completed, Average Loss: 19.89306926727295\n",
      "Validation Loss after Epoch 21/200: 9.953024864196777\n",
      "\n",
      "Epoch 22/200, Batch 1/4, Loss: 19.9732666015625\n",
      "Epoch 22/200 completed, Average Loss: 19.88813877105713\n",
      "Validation Loss after Epoch 22/200: 9.953545093536377\n",
      "\n",
      "Epoch 23/200, Batch 1/4, Loss: 19.83047866821289\n",
      "Epoch 23/200 completed, Average Loss: 19.88947868347168\n",
      "Validation Loss after Epoch 23/200: 9.94966745376587\n",
      "\n",
      "Epoch 24/200, Batch 1/4, Loss: 19.86541748046875\n",
      "Epoch 24/200 completed, Average Loss: 19.883605003356934\n",
      "Validation Loss after Epoch 24/200: 9.949441909790039\n",
      "\n",
      "Epoch 25/200, Batch 1/4, Loss: 19.98960304260254\n",
      "Epoch 25/200 completed, Average Loss: 19.887261390686035\n",
      "Validation Loss after Epoch 25/200: 9.949383735656738\n",
      "\n",
      "Epoch 26/200, Batch 1/4, Loss: 20.07162857055664\n",
      "Epoch 26/200 completed, Average Loss: 19.884591579437256\n",
      "Validation Loss after Epoch 26/200: 9.94924020767212\n",
      "\n",
      "Epoch 27/200, Batch 1/4, Loss: 19.801334381103516\n",
      "Epoch 27/200 completed, Average Loss: 19.879568099975586\n",
      "Validation Loss after Epoch 27/200: 9.950015544891357\n",
      "\n",
      "Epoch 28/200, Batch 1/4, Loss: 19.778705596923828\n",
      "Epoch 28/200 completed, Average Loss: 19.88605546951294\n",
      "Validation Loss after Epoch 28/200: 9.951564311981201\n",
      "\n",
      "Epoch 29/200, Batch 1/4, Loss: 19.814945220947266\n",
      "Epoch 29/200 completed, Average Loss: 19.881447315216064\n",
      "Validation Loss after Epoch 29/200: 9.951121807098389\n",
      "\n",
      "Epoch 30/200, Batch 1/4, Loss: 19.99991226196289\n",
      "Epoch 30/200 completed, Average Loss: 19.87981414794922\n",
      "Validation Loss after Epoch 30/200: 9.951087951660156\n",
      "\n",
      "Epoch 31/200, Batch 1/4, Loss: 20.035900115966797\n",
      "Epoch 31/200 completed, Average Loss: 19.879740238189697\n",
      "Validation Loss after Epoch 31/200: 9.951087951660156\n",
      "\n",
      "Epoch 32/200, Batch 1/4, Loss: 20.042564392089844\n",
      "Epoch 32/200 completed, Average Loss: 19.880016326904297\n",
      "Validation Loss after Epoch 32/200: 9.950946807861328\n",
      "\n",
      "Epoch 33/200, Batch 1/4, Loss: 20.152719497680664\n",
      "Epoch 33/200 completed, Average Loss: 19.87991952896118\n",
      "Validation Loss after Epoch 33/200: 9.950785160064697\n",
      "\n",
      "Epoch 34/200, Batch 1/4, Loss: 19.988269805908203\n",
      "Epoch 34/200 completed, Average Loss: 19.879415035247803\n",
      "Validation Loss after Epoch 34/200: 9.950393676757812\n",
      "\n",
      "Epoch 35/200, Batch 1/4, Loss: 19.83336639404297\n",
      "Epoch 35/200 completed, Average Loss: 19.87855339050293\n",
      "Validation Loss after Epoch 35/200: 9.94977617263794\n",
      "\n",
      "Epoch 36/200, Batch 1/4, Loss: 19.855548858642578\n",
      "Epoch 36/200 completed, Average Loss: 19.87859535217285\n",
      "Validation Loss after Epoch 36/200: 9.949236392974854\n",
      "\n",
      "Epoch 37/200, Batch 1/4, Loss: 19.89777374267578\n",
      "Epoch 37/200 completed, Average Loss: 19.881246089935303\n",
      "Validation Loss after Epoch 37/200: 9.949304103851318\n",
      "\n",
      "Epoch 38/200, Batch 1/4, Loss: 19.807310104370117\n",
      "Epoch 38/200 completed, Average Loss: 19.883267402648926\n",
      "Validation Loss after Epoch 38/200: 9.950291633605957\n",
      "\n",
      "Epoch 39/200, Batch 1/4, Loss: 19.76506805419922\n",
      "Epoch 39/200 completed, Average Loss: 19.87903881072998\n",
      "Validation Loss after Epoch 39/200: 9.949551582336426\n",
      "\n",
      "Epoch 40/200, Batch 1/4, Loss: 19.90472412109375\n",
      "Epoch 40/200 completed, Average Loss: 19.877312183380127\n",
      "Validation Loss after Epoch 40/200: 9.949036121368408\n",
      "\n",
      "Epoch 41/200, Batch 1/4, Loss: 20.111190795898438\n",
      "Epoch 41/200 completed, Average Loss: 19.894161224365234\n",
      "Validation Loss after Epoch 41/200: 9.949076652526855\n",
      "\n",
      "Epoch 42/200, Batch 1/4, Loss: 20.031902313232422\n",
      "Epoch 42/200 completed, Average Loss: 19.887898921966553\n",
      "Validation Loss after Epoch 42/200: 9.958152770996094\n",
      "\n",
      "Epoch 43/200, Batch 1/4, Loss: 19.939407348632812\n",
      "Epoch 43/200 completed, Average Loss: 19.90032196044922\n",
      "Validation Loss after Epoch 43/200: 9.953802108764648\n",
      "\n",
      "Epoch 44/200, Batch 1/4, Loss: 19.867385864257812\n",
      "Epoch 44/200 completed, Average Loss: 19.864713191986084\n",
      "Validation Loss after Epoch 44/200: 9.95780897140503\n",
      "\n",
      "Epoch 45/200, Batch 1/4, Loss: 19.898101806640625\n",
      "Epoch 45/200 completed, Average Loss: 19.88828134536743\n",
      "Validation Loss after Epoch 45/200: 9.954375267028809\n",
      "\n",
      "Epoch 46/200, Batch 1/4, Loss: 19.850845336914062\n",
      "Epoch 46/200 completed, Average Loss: 19.900558471679688\n",
      "Validation Loss after Epoch 46/200: 9.952245712280273\n",
      "\n",
      "Epoch 47/200, Batch 1/4, Loss: 19.897809982299805\n",
      "Epoch 47/200 completed, Average Loss: 19.938695907592773\n",
      "Validation Loss after Epoch 47/200: 9.967330932617188\n",
      "\n",
      "Epoch 48/200, Batch 1/4, Loss: 19.95074462890625\n",
      "Epoch 48/200 completed, Average Loss: 20.01756238937378\n",
      "Validation Loss after Epoch 48/200: 9.959455013275146\n",
      "\n",
      "Epoch 49/200, Batch 1/4, Loss: 19.991352081298828\n",
      "Epoch 49/200 completed, Average Loss: 19.939207077026367\n",
      "Validation Loss after Epoch 49/200: 9.990435123443604\n",
      "\n",
      "Epoch 50/200, Batch 1/4, Loss: 20.012136459350586\n",
      "Epoch 50/200 completed, Average Loss: 19.973623752593994\n",
      "Validation Loss after Epoch 50/200: 9.96796464920044\n",
      "\n",
      "Epoch 51/200, Batch 1/4, Loss: 19.844907760620117\n",
      "Epoch 51/200 completed, Average Loss: 19.908315181732178\n",
      "Validation Loss after Epoch 51/200: 9.991529941558838\n",
      "\n",
      "Epoch 52/200, Batch 1/4, Loss: 19.834774017333984\n",
      "Epoch 52/200 completed, Average Loss: 19.888599395751953\n",
      "Validation Loss after Epoch 52/200: 9.960962295532227\n",
      "\n",
      "Epoch 53/200, Batch 1/4, Loss: 19.94400405883789\n",
      "Epoch 53/200 completed, Average Loss: 19.92358636856079\n",
      "Validation Loss after Epoch 53/200: 9.963041305541992\n",
      "\n",
      "Epoch 54/200, Batch 1/4, Loss: 19.850645065307617\n",
      "Epoch 54/200 completed, Average Loss: 19.97657871246338\n",
      "Validation Loss after Epoch 54/200: 9.988694667816162\n",
      "\n",
      "Epoch 55/200, Batch 1/4, Loss: 19.675373077392578\n",
      "Epoch 55/200 completed, Average Loss: 19.978503704071045\n",
      "Validation Loss after Epoch 55/200: 9.978421211242676\n",
      "\n",
      "Epoch 56/200, Batch 1/4, Loss: 19.8817138671875\n",
      "Epoch 56/200 completed, Average Loss: 20.121325492858887\n",
      "Validation Loss after Epoch 56/200: 9.99100112915039\n",
      "\n",
      "Epoch 57/200, Batch 1/4, Loss: 19.871192932128906\n",
      "Epoch 57/200 completed, Average Loss: 20.05587148666382\n",
      "Validation Loss after Epoch 57/200: 10.015145301818848\n",
      "\n",
      "Epoch 58/200, Batch 1/4, Loss: 19.775117874145508\n",
      "Epoch 58/200 completed, Average Loss: 20.036036014556885\n",
      "Validation Loss after Epoch 58/200: 10.024796962738037\n",
      "\n",
      "Epoch 59/200, Batch 1/4, Loss: 20.256813049316406\n",
      "Epoch 59/200 completed, Average Loss: 19.924789428710938\n",
      "Validation Loss after Epoch 59/200: 9.998414993286133\n",
      "\n",
      "Epoch 60/200, Batch 1/4, Loss: 19.518815994262695\n",
      "Epoch 60/200 completed, Average Loss: 20.02273464202881\n",
      "Validation Loss after Epoch 60/200: 10.017304420471191\n",
      "\n",
      "Epoch 61/200, Batch 1/4, Loss: 19.836450576782227\n",
      "Epoch 61/200 completed, Average Loss: 20.005049228668213\n",
      "Validation Loss after Epoch 61/200: 9.981836795806885\n",
      "\n",
      "Epoch 62/200, Batch 1/4, Loss: 19.7249755859375\n",
      "Epoch 62/200 completed, Average Loss: 19.822471618652344\n",
      "Validation Loss after Epoch 62/200: 9.992455005645752\n",
      "\n",
      "Epoch 63/200, Batch 1/4, Loss: 19.963531494140625\n",
      "Epoch 63/200 completed, Average Loss: 19.827267169952393\n",
      "Validation Loss after Epoch 63/200: 10.074170589447021\n",
      "\n",
      "Epoch 64/200, Batch 1/4, Loss: 19.819599151611328\n",
      "Epoch 64/200 completed, Average Loss: 19.907431602478027\n",
      "Validation Loss after Epoch 64/200: 10.006208896636963\n",
      "\n",
      "Epoch 65/200, Batch 1/4, Loss: 19.845592498779297\n",
      "Epoch 65/200 completed, Average Loss: 20.00423002243042\n",
      "Validation Loss after Epoch 65/200: 10.015796661376953\n",
      "\n",
      "Epoch 66/200, Batch 1/4, Loss: 19.600128173828125\n",
      "Epoch 66/200 completed, Average Loss: 20.00465488433838\n",
      "Validation Loss after Epoch 66/200: 10.00184440612793\n",
      "\n",
      "Epoch 67/200, Batch 1/4, Loss: 19.893173217773438\n",
      "Epoch 67/200 completed, Average Loss: 19.858545780181885\n",
      "Validation Loss after Epoch 67/200: 10.027493476867676\n",
      "\n",
      "Epoch 68/200, Batch 1/4, Loss: 19.813461303710938\n",
      "Epoch 68/200 completed, Average Loss: 19.887049198150635\n",
      "Validation Loss after Epoch 68/200: 10.046253204345703\n",
      "\n",
      "Epoch 69/200, Batch 1/4, Loss: 19.336130142211914\n",
      "Epoch 69/200 completed, Average Loss: 19.72867727279663\n",
      "Validation Loss after Epoch 69/200: 10.046310901641846\n",
      "\n",
      "Epoch 70/200, Batch 1/4, Loss: 19.779335021972656\n",
      "Epoch 70/200 completed, Average Loss: 19.749849319458008\n",
      "Validation Loss after Epoch 70/200: 10.04329538345337\n",
      "\n",
      "Epoch 71/200, Batch 1/4, Loss: 19.737300872802734\n",
      "Epoch 71/200 completed, Average Loss: 19.67626428604126\n",
      "Validation Loss after Epoch 71/200: 10.042354106903076\n",
      "\n",
      "Epoch 72/200, Batch 1/4, Loss: 19.45833969116211\n",
      "Epoch 72/200 completed, Average Loss: 19.681589603424072\n",
      "Validation Loss after Epoch 72/200: 10.049309730529785\n",
      "\n",
      "Epoch 73/200, Batch 1/4, Loss: 19.88402557373047\n",
      "Epoch 73/200 completed, Average Loss: 19.65619659423828\n",
      "Validation Loss after Epoch 73/200: 10.052310943603516\n",
      "\n",
      "Epoch 74/200, Batch 1/4, Loss: 19.57862663269043\n",
      "Epoch 74/200 completed, Average Loss: 19.636744022369385\n",
      "Validation Loss after Epoch 74/200: 10.064231395721436\n",
      "\n",
      "Epoch 75/200, Batch 1/4, Loss: 19.584026336669922\n",
      "Epoch 75/200 completed, Average Loss: 19.654253482818604\n",
      "Validation Loss after Epoch 75/200: 10.065937519073486\n",
      "\n",
      "Epoch 76/200, Batch 1/4, Loss: 19.494234085083008\n",
      "Epoch 76/200 completed, Average Loss: 19.596009731292725\n",
      "Validation Loss after Epoch 76/200: 10.061612606048584\n",
      "\n",
      "Epoch 77/200, Batch 1/4, Loss: 19.620656967163086\n",
      "Epoch 77/200 completed, Average Loss: 19.624107837677002\n",
      "Validation Loss after Epoch 77/200: 10.082074165344238\n",
      "\n",
      "Epoch 78/200, Batch 1/4, Loss: 19.28074073791504\n",
      "Epoch 78/200 completed, Average Loss: 19.59479284286499\n",
      "Validation Loss after Epoch 78/200: 10.081060409545898\n",
      "\n",
      "Epoch 79/200, Batch 1/4, Loss: 19.447891235351562\n",
      "Epoch 79/200 completed, Average Loss: 19.592236042022705\n",
      "Validation Loss after Epoch 79/200: 10.075215339660645\n",
      "\n",
      "Epoch 80/200, Batch 1/4, Loss: 19.873550415039062\n",
      "Epoch 80/200 completed, Average Loss: 19.599435329437256\n",
      "Validation Loss after Epoch 80/200: 10.084701538085938\n",
      "\n",
      "Epoch 81/200, Batch 1/4, Loss: 19.370983123779297\n",
      "Epoch 81/200 completed, Average Loss: 19.56330680847168\n",
      "Validation Loss after Epoch 81/200: 10.086932182312012\n",
      "\n",
      "Epoch 82/200, Batch 1/4, Loss: 19.494277954101562\n",
      "Epoch 82/200 completed, Average Loss: 19.550854682922363\n",
      "Validation Loss after Epoch 82/200: 10.08218002319336\n",
      "\n",
      "Epoch 83/200, Batch 1/4, Loss: 19.610088348388672\n",
      "Epoch 83/200 completed, Average Loss: 19.550291538238525\n",
      "Validation Loss after Epoch 83/200: 10.098044395446777\n",
      "\n",
      "Epoch 84/200, Batch 1/4, Loss: 19.47249984741211\n",
      "Epoch 84/200 completed, Average Loss: 19.54508066177368\n",
      "Validation Loss after Epoch 84/200: 10.09307861328125\n",
      "\n",
      "Epoch 85/200, Batch 1/4, Loss: 19.432735443115234\n",
      "Epoch 85/200 completed, Average Loss: 19.5301775932312\n",
      "Validation Loss after Epoch 85/200: 10.094042778015137\n",
      "\n",
      "Epoch 86/200, Batch 1/4, Loss: 19.743484497070312\n",
      "Epoch 86/200 completed, Average Loss: 19.529611587524414\n",
      "Validation Loss after Epoch 86/200: 10.097622394561768\n",
      "\n",
      "Epoch 87/200, Batch 1/4, Loss: 19.832908630371094\n",
      "Epoch 87/200 completed, Average Loss: 19.53398561477661\n",
      "Validation Loss after Epoch 87/200: 10.097135066986084\n",
      "\n",
      "Epoch 88/200, Batch 1/4, Loss: 19.566082000732422\n",
      "Epoch 88/200 completed, Average Loss: 19.525726318359375\n",
      "Validation Loss after Epoch 88/200: 10.097248077392578\n",
      "\n",
      "Epoch 89/200, Batch 1/4, Loss: 19.538227081298828\n",
      "Epoch 89/200 completed, Average Loss: 19.525437831878662\n",
      "Validation Loss after Epoch 89/200: 10.097430229187012\n",
      "\n",
      "Epoch 90/200, Batch 1/4, Loss: 19.410099029541016\n",
      "Epoch 90/200 completed, Average Loss: 19.52242612838745\n",
      "Validation Loss after Epoch 90/200: 10.097573280334473\n",
      "\n",
      "Epoch 91/200, Batch 1/4, Loss: 19.585166931152344\n",
      "Epoch 91/200 completed, Average Loss: 19.522117137908936\n",
      "Validation Loss after Epoch 91/200: 10.097572803497314\n",
      "\n",
      "Epoch 92/200, Batch 1/4, Loss: 19.518253326416016\n",
      "Epoch 92/200 completed, Average Loss: 19.522420406341553\n",
      "Validation Loss after Epoch 92/200: 10.097554206848145\n",
      "\n",
      "Epoch 93/200, Batch 1/4, Loss: 19.289348602294922\n",
      "Epoch 93/200 completed, Average Loss: 19.52560520172119\n",
      "Validation Loss after Epoch 93/200: 10.097968578338623\n",
      "\n",
      "Epoch 94/200, Batch 1/4, Loss: 19.538963317871094\n",
      "Epoch 94/200 completed, Average Loss: 19.52282476425171\n",
      "Validation Loss after Epoch 94/200: 10.097442626953125\n",
      "\n",
      "Epoch 95/200, Batch 1/4, Loss: 19.6988525390625\n",
      "Epoch 95/200 completed, Average Loss: 19.52239751815796\n",
      "Validation Loss after Epoch 95/200: 10.098625183105469\n",
      "\n",
      "Epoch 96/200, Batch 1/4, Loss: 19.316003799438477\n",
      "Epoch 96/200 completed, Average Loss: 19.52188730239868\n",
      "Validation Loss after Epoch 96/200: 10.103012561798096\n",
      "\n",
      "Epoch 97/200, Batch 1/4, Loss: 19.273712158203125\n",
      "Epoch 97/200 completed, Average Loss: 19.523280143737793\n",
      "Validation Loss after Epoch 97/200: 10.104132652282715\n",
      "\n",
      "Epoch 98/200, Batch 1/4, Loss: 19.887718200683594\n",
      "Epoch 98/200 completed, Average Loss: 19.522124767303467\n",
      "Validation Loss after Epoch 98/200: 10.103471755981445\n",
      "\n",
      "Epoch 99/200, Batch 1/4, Loss: 19.54117202758789\n",
      "Epoch 99/200 completed, Average Loss: 19.51961040496826\n",
      "Validation Loss after Epoch 99/200: 10.108755111694336\n",
      "\n",
      "Epoch 100/200, Batch 1/4, Loss: 19.488235473632812\n",
      "Epoch 100/200 completed, Average Loss: 19.511838912963867\n",
      "Validation Loss after Epoch 100/200: 10.115044593811035\n",
      "\n",
      "Epoch 101/200, Batch 1/4, Loss: 19.645174026489258\n",
      "Epoch 101/200 completed, Average Loss: 19.511273860931396\n",
      "Validation Loss after Epoch 101/200: 10.113654613494873\n",
      "\n",
      "Epoch 102/200, Batch 1/4, Loss: 19.434612274169922\n",
      "Epoch 102/200 completed, Average Loss: 19.53217601776123\n",
      "Validation Loss after Epoch 102/200: 10.11225700378418\n",
      "\n",
      "Epoch 103/200, Batch 1/4, Loss: 19.633325576782227\n",
      "Epoch 103/200 completed, Average Loss: 19.50241756439209\n",
      "Validation Loss after Epoch 103/200: 10.10897970199585\n",
      "\n",
      "Epoch 104/200, Batch 1/4, Loss: 19.343948364257812\n",
      "Epoch 104/200 completed, Average Loss: 19.494336128234863\n",
      "Validation Loss after Epoch 104/200: 10.125630378723145\n",
      "\n",
      "Epoch 105/200, Batch 1/4, Loss: 19.675737380981445\n",
      "Epoch 105/200 completed, Average Loss: 19.50603199005127\n",
      "Validation Loss after Epoch 105/200: 10.14268684387207\n",
      "\n",
      "Epoch 106/200, Batch 1/4, Loss: 19.29568099975586\n",
      "Epoch 106/200 completed, Average Loss: 19.488839149475098\n",
      "Validation Loss after Epoch 106/200: 10.119705200195312\n",
      "\n",
      "Epoch 107/200, Batch 1/4, Loss: 19.50592041015625\n",
      "Epoch 107/200 completed, Average Loss: 19.461331844329834\n",
      "Validation Loss after Epoch 107/200: 10.142965316772461\n",
      "\n",
      "Epoch 108/200, Batch 1/4, Loss: 19.44780158996582\n",
      "Epoch 108/200 completed, Average Loss: 19.460227489471436\n",
      "Validation Loss after Epoch 108/200: 10.192049026489258\n",
      "\n",
      "Epoch 109/200, Batch 1/4, Loss: 19.66519546508789\n",
      "Epoch 109/200 completed, Average Loss: 19.526570320129395\n",
      "Validation Loss after Epoch 109/200: 10.13744831085205\n",
      "\n",
      "Epoch 110/200, Batch 1/4, Loss: 19.28374481201172\n",
      "Epoch 110/200 completed, Average Loss: 19.55610704421997\n",
      "Validation Loss after Epoch 110/200: 10.172913551330566\n",
      "\n",
      "Epoch 111/200, Batch 1/4, Loss: 19.70081901550293\n",
      "Epoch 111/200 completed, Average Loss: 19.51361846923828\n",
      "Validation Loss after Epoch 111/200: 10.214248657226562\n",
      "\n",
      "Epoch 112/200, Batch 1/4, Loss: 19.4415283203125\n",
      "Epoch 112/200 completed, Average Loss: 19.44681215286255\n",
      "Validation Loss after Epoch 112/200: 10.15261459350586\n",
      "\n",
      "Epoch 113/200, Batch 1/4, Loss: 19.231948852539062\n",
      "Epoch 113/200 completed, Average Loss: 19.443735122680664\n",
      "Validation Loss after Epoch 113/200: 10.17603588104248\n",
      "\n",
      "Epoch 114/200, Batch 1/4, Loss: 19.217376708984375\n",
      "Epoch 114/200 completed, Average Loss: 19.328851222991943\n",
      "Validation Loss after Epoch 114/200: 10.202306747436523\n",
      "\n",
      "Epoch 115/200, Batch 1/4, Loss: 19.4589900970459\n",
      "Epoch 115/200 completed, Average Loss: 19.357866287231445\n",
      "Validation Loss after Epoch 115/200: 10.20011043548584\n",
      "\n",
      "Epoch 116/200, Batch 1/4, Loss: 19.286340713500977\n",
      "Epoch 116/200 completed, Average Loss: 19.339715003967285\n",
      "Validation Loss after Epoch 116/200: 10.322474956512451\n",
      "\n",
      "Epoch 117/200, Batch 1/4, Loss: 19.05759620666504\n",
      "Epoch 117/200 completed, Average Loss: 19.48568820953369\n",
      "Validation Loss after Epoch 117/200: 10.197144508361816\n",
      "\n",
      "Epoch 118/200, Batch 1/4, Loss: 19.6221981048584\n",
      "Epoch 118/200 completed, Average Loss: 19.664106369018555\n",
      "Validation Loss after Epoch 118/200: 10.100031852722168\n",
      "\n",
      "Epoch 119/200, Batch 1/4, Loss: 19.148305892944336\n",
      "Epoch 119/200 completed, Average Loss: 19.619353771209717\n",
      "Validation Loss after Epoch 119/200: 10.030263900756836\n",
      "\n",
      "Epoch 120/200, Batch 1/4, Loss: 19.10629653930664\n",
      "Epoch 120/200 completed, Average Loss: 19.505104064941406\n",
      "Validation Loss after Epoch 120/200: 10.360098838806152\n",
      "\n",
      "Epoch 121/200, Batch 1/4, Loss: 19.61450958251953\n",
      "Epoch 121/200 completed, Average Loss: 19.625142097473145\n",
      "Validation Loss after Epoch 121/200: 10.01894235610962\n",
      "\n",
      "Epoch 122/200, Batch 1/4, Loss: 19.5773868560791\n",
      "Epoch 122/200 completed, Average Loss: 19.68343734741211\n",
      "Validation Loss after Epoch 122/200: 10.167611122131348\n",
      "\n",
      "Epoch 123/200, Batch 1/4, Loss: 19.135143280029297\n",
      "Epoch 123/200 completed, Average Loss: 19.60299015045166\n",
      "Validation Loss after Epoch 123/200: 10.091472148895264\n",
      "\n",
      "Epoch 124/200, Batch 1/4, Loss: 19.585567474365234\n",
      "Epoch 124/200 completed, Average Loss: 19.565914154052734\n",
      "Validation Loss after Epoch 124/200: 10.291303157806396\n",
      "\n",
      "Epoch 125/200, Batch 1/4, Loss: 19.456451416015625\n",
      "Epoch 125/200 completed, Average Loss: 19.486053943634033\n",
      "Validation Loss after Epoch 125/200: 10.050881385803223\n",
      "\n",
      "Epoch 126/200, Batch 1/4, Loss: 19.38660430908203\n",
      "Epoch 126/200 completed, Average Loss: 19.411216735839844\n",
      "Validation Loss after Epoch 126/200: 10.114616394042969\n",
      "\n",
      "Epoch 127/200, Batch 1/4, Loss: 19.24612045288086\n",
      "Epoch 127/200 completed, Average Loss: 19.266874313354492\n",
      "Validation Loss after Epoch 127/200: 10.147215843200684\n",
      "\n",
      "Epoch 128/200, Batch 1/4, Loss: 19.214702606201172\n",
      "Epoch 128/200 completed, Average Loss: 19.374143600463867\n",
      "Validation Loss after Epoch 128/200: 10.10330867767334\n",
      "\n",
      "Epoch 129/200, Batch 1/4, Loss: 19.537460327148438\n",
      "Epoch 129/200 completed, Average Loss: 19.359586238861084\n",
      "Validation Loss after Epoch 129/200: 10.148121356964111\n",
      "\n",
      "Epoch 130/200, Batch 1/4, Loss: 18.955371856689453\n",
      "Epoch 130/200 completed, Average Loss: 19.237297534942627\n",
      "Validation Loss after Epoch 130/200: 10.10922908782959\n",
      "\n",
      "Epoch 131/200, Batch 1/4, Loss: 18.787084579467773\n",
      "Epoch 131/200 completed, Average Loss: 19.172306060791016\n",
      "Validation Loss after Epoch 131/200: 10.248630046844482\n",
      "\n",
      "Epoch 132/200, Batch 1/4, Loss: 19.31903648376465\n",
      "Epoch 132/200 completed, Average Loss: 19.172364711761475\n",
      "Validation Loss after Epoch 132/200: 10.118772506713867\n",
      "\n",
      "Epoch 133/200, Batch 1/4, Loss: 19.11370277404785\n",
      "Epoch 133/200 completed, Average Loss: 19.090980052947998\n",
      "Validation Loss after Epoch 133/200: 10.218316555023193\n",
      "\n",
      "Epoch 134/200, Batch 1/4, Loss: 18.825908660888672\n",
      "Epoch 134/200 completed, Average Loss: 19.083702087402344\n",
      "Validation Loss after Epoch 134/200: 10.135115623474121\n",
      "\n",
      "Epoch 135/200, Batch 1/4, Loss: 19.261045455932617\n",
      "Epoch 135/200 completed, Average Loss: 18.967214584350586\n",
      "Validation Loss after Epoch 135/200: 10.382725715637207\n",
      "\n",
      "Epoch 136/200, Batch 1/4, Loss: 19.003015518188477\n",
      "Epoch 136/200 completed, Average Loss: 18.975452423095703\n",
      "Validation Loss after Epoch 136/200: 10.169182777404785\n",
      "\n",
      "Epoch 137/200, Batch 1/4, Loss: 19.37688446044922\n",
      "Epoch 137/200 completed, Average Loss: 18.903769969940186\n",
      "Validation Loss after Epoch 137/200: 10.281363010406494\n",
      "\n",
      "Epoch 138/200, Batch 1/4, Loss: 18.7125301361084\n",
      "Epoch 138/200 completed, Average Loss: 18.861809730529785\n",
      "Validation Loss after Epoch 138/200: 10.245096683502197\n",
      "\n",
      "Epoch 139/200, Batch 1/4, Loss: 18.802318572998047\n",
      "Epoch 139/200 completed, Average Loss: 18.796360969543457\n",
      "Validation Loss after Epoch 139/200: 10.286369323730469\n",
      "\n",
      "Epoch 140/200, Batch 1/4, Loss: 19.001811981201172\n",
      "Epoch 140/200 completed, Average Loss: 18.761213779449463\n",
      "Validation Loss after Epoch 140/200: 10.298422813415527\n",
      "\n",
      "Epoch 141/200, Batch 1/4, Loss: 18.765682220458984\n",
      "Epoch 141/200 completed, Average Loss: 18.734394073486328\n",
      "Validation Loss after Epoch 141/200: 10.230362892150879\n",
      "\n",
      "Epoch 142/200, Batch 1/4, Loss: 18.22803497314453\n",
      "Epoch 142/200 completed, Average Loss: 18.716006755828857\n",
      "Validation Loss after Epoch 142/200: 10.283824920654297\n",
      "\n",
      "Epoch 143/200, Batch 1/4, Loss: 18.7017879486084\n",
      "Epoch 143/200 completed, Average Loss: 18.733829975128174\n",
      "Validation Loss after Epoch 143/200: 10.277142524719238\n",
      "\n",
      "Epoch 144/200, Batch 1/4, Loss: 18.318784713745117\n",
      "Epoch 144/200 completed, Average Loss: 18.69556999206543\n",
      "Validation Loss after Epoch 144/200: 10.269909381866455\n",
      "\n",
      "Epoch 145/200, Batch 1/4, Loss: 18.66865348815918\n",
      "Epoch 145/200 completed, Average Loss: 18.674760818481445\n",
      "Validation Loss after Epoch 145/200: 10.29109001159668\n",
      "\n",
      "Epoch 146/200, Batch 1/4, Loss: 18.65692901611328\n",
      "Epoch 146/200 completed, Average Loss: 18.65461540222168\n",
      "Validation Loss after Epoch 146/200: 10.305793285369873\n",
      "\n",
      "Epoch 147/200, Batch 1/4, Loss: 18.0003719329834\n",
      "Epoch 147/200 completed, Average Loss: 18.64150047302246\n",
      "Validation Loss after Epoch 147/200: 10.308541774749756\n",
      "\n",
      "Epoch 148/200, Batch 1/4, Loss: 18.26493263244629\n",
      "Epoch 148/200 completed, Average Loss: 18.63699436187744\n",
      "Validation Loss after Epoch 148/200: 10.309126377105713\n",
      "\n",
      "Epoch 149/200, Batch 1/4, Loss: 18.70006561279297\n",
      "Epoch 149/200 completed, Average Loss: 18.628446578979492\n",
      "Validation Loss after Epoch 149/200: 10.308616638183594\n",
      "\n",
      "Epoch 150/200, Batch 1/4, Loss: 18.093006134033203\n",
      "Epoch 150/200 completed, Average Loss: 18.626325607299805\n",
      "Validation Loss after Epoch 150/200: 10.308120727539062\n",
      "\n",
      "Epoch 151/200, Batch 1/4, Loss: 18.518590927124023\n",
      "Epoch 151/200 completed, Average Loss: 18.625729084014893\n",
      "Validation Loss after Epoch 151/200: 10.308120250701904\n",
      "\n",
      "Epoch 152/200, Batch 1/4, Loss: 18.352123260498047\n",
      "Epoch 152/200 completed, Average Loss: 18.62573766708374\n",
      "Validation Loss after Epoch 152/200: 10.308204174041748\n",
      "\n",
      "Epoch 153/200, Batch 1/4, Loss: 18.46401596069336\n",
      "Epoch 153/200 completed, Average Loss: 18.62503480911255\n",
      "Validation Loss after Epoch 153/200: 10.30728530883789\n",
      "\n",
      "Epoch 154/200, Batch 1/4, Loss: 18.50881004333496\n",
      "Epoch 154/200 completed, Average Loss: 18.62424087524414\n",
      "Validation Loss after Epoch 154/200: 10.30694580078125\n",
      "\n",
      "Epoch 155/200, Batch 1/4, Loss: 18.676124572753906\n",
      "Epoch 155/200 completed, Average Loss: 18.618954181671143\n",
      "Validation Loss after Epoch 155/200: 10.306702136993408\n",
      "\n",
      "Epoch 156/200, Batch 1/4, Loss: 18.65809440612793\n",
      "Epoch 156/200 completed, Average Loss: 18.61440134048462\n",
      "Validation Loss after Epoch 156/200: 10.30424690246582\n",
      "\n",
      "Epoch 157/200, Batch 1/4, Loss: 18.565670013427734\n",
      "Epoch 157/200 completed, Average Loss: 18.611793994903564\n",
      "Validation Loss after Epoch 157/200: 10.299180507659912\n",
      "\n",
      "Epoch 158/200, Batch 1/4, Loss: 18.41522789001465\n",
      "Epoch 158/200 completed, Average Loss: 18.602436542510986\n",
      "Validation Loss after Epoch 158/200: 10.301810264587402\n",
      "\n",
      "Epoch 159/200, Batch 1/4, Loss: 18.296314239501953\n",
      "Epoch 159/200 completed, Average Loss: 18.59483242034912\n",
      "Validation Loss after Epoch 159/200: 10.316798210144043\n",
      "\n",
      "Epoch 160/200, Batch 1/4, Loss: 18.869810104370117\n",
      "Epoch 160/200 completed, Average Loss: 18.594491004943848\n",
      "Validation Loss after Epoch 160/200: 10.28946590423584\n",
      "\n",
      "Epoch 161/200, Batch 1/4, Loss: 18.476478576660156\n",
      "Epoch 161/200 completed, Average Loss: 18.5762038230896\n",
      "Validation Loss after Epoch 161/200: 10.34455394744873\n",
      "\n",
      "Epoch 162/200, Batch 1/4, Loss: 18.817214965820312\n",
      "Epoch 162/200 completed, Average Loss: 18.55932903289795\n",
      "Validation Loss after Epoch 162/200: 10.29964542388916\n",
      "\n",
      "Epoch 163/200, Batch 1/4, Loss: 17.87942886352539\n",
      "Epoch 163/200 completed, Average Loss: 18.546226024627686\n",
      "Validation Loss after Epoch 163/200: 10.360936641693115\n",
      "\n",
      "Epoch 164/200, Batch 1/4, Loss: 18.521608352661133\n",
      "Epoch 164/200 completed, Average Loss: 18.530698776245117\n",
      "Validation Loss after Epoch 164/200: 10.312078475952148\n",
      "\n",
      "Epoch 165/200, Batch 1/4, Loss: 18.022666931152344\n",
      "Epoch 165/200 completed, Average Loss: 18.5276517868042\n",
      "Validation Loss after Epoch 165/200: 10.431154727935791\n",
      "\n",
      "Epoch 166/200, Batch 1/4, Loss: 18.21222496032715\n",
      "Epoch 166/200 completed, Average Loss: 18.55752992630005\n",
      "Validation Loss after Epoch 166/200: 10.289238452911377\n",
      "\n",
      "Epoch 167/200, Batch 1/4, Loss: 18.166677474975586\n",
      "Epoch 167/200 completed, Average Loss: 18.660595893859863\n",
      "Validation Loss after Epoch 167/200: 10.372499465942383\n",
      "\n",
      "Epoch 168/200, Batch 1/4, Loss: 18.118968963623047\n",
      "Epoch 168/200 completed, Average Loss: 18.645540237426758\n",
      "Validation Loss after Epoch 168/200: 10.495244026184082\n",
      "\n",
      "Epoch 169/200, Batch 1/4, Loss: 18.825267791748047\n",
      "Epoch 169/200 completed, Average Loss: 19.01199245452881\n",
      "Validation Loss after Epoch 169/200: 10.303494453430176\n",
      "\n",
      "Epoch 170/200, Batch 1/4, Loss: 19.389923095703125\n",
      "Epoch 170/200 completed, Average Loss: 20.895544052124023\n",
      "Validation Loss after Epoch 170/200: 10.022511005401611\n",
      "\n",
      "Epoch 171/200, Batch 1/4, Loss: 20.06233787536621\n",
      "Epoch 171/200 completed, Average Loss: 20.009482383728027\n",
      "Validation Loss after Epoch 171/200: 10.000730514526367\n",
      "\n",
      "Epoch 172/200, Batch 1/4, Loss: 19.932926177978516\n",
      "Epoch 172/200 completed, Average Loss: 20.069075107574463\n",
      "Validation Loss after Epoch 172/200: 10.022282600402832\n",
      "\n",
      "Epoch 173/200, Batch 1/4, Loss: 20.254323959350586\n",
      "Epoch 173/200 completed, Average Loss: 20.19334888458252\n",
      "Validation Loss after Epoch 173/200: 10.22057819366455\n",
      "\n",
      "Epoch 174/200, Batch 1/4, Loss: 20.392513275146484\n",
      "Epoch 174/200 completed, Average Loss: 20.244372844696045\n",
      "Validation Loss after Epoch 174/200: 10.012791633605957\n",
      "\n",
      "Epoch 175/200, Batch 1/4, Loss: 20.033077239990234\n",
      "Epoch 175/200 completed, Average Loss: 20.125926971435547\n",
      "Validation Loss after Epoch 175/200: 10.016509056091309\n",
      "\n",
      "Epoch 176/200, Batch 1/4, Loss: 20.056455612182617\n",
      "Epoch 176/200 completed, Average Loss: 20.015085220336914\n",
      "Validation Loss after Epoch 176/200: 9.999276161193848\n",
      "\n",
      "Epoch 177/200, Batch 1/4, Loss: 19.996597290039062\n",
      "Epoch 177/200 completed, Average Loss: 20.035123348236084\n",
      "Validation Loss after Epoch 177/200: 10.002784729003906\n",
      "\n",
      "Epoch 178/200, Batch 1/4, Loss: 20.00954818725586\n",
      "Epoch 178/200 completed, Average Loss: 19.998385429382324\n",
      "Validation Loss after Epoch 178/200: 10.008189678192139\n",
      "\n",
      "Epoch 179/200, Batch 1/4, Loss: 20.108259201049805\n",
      "Epoch 179/200 completed, Average Loss: 20.02854299545288\n",
      "Validation Loss after Epoch 179/200: 9.997406482696533\n",
      "\n",
      "Epoch 180/200, Batch 1/4, Loss: 19.993663787841797\n",
      "Epoch 180/200 completed, Average Loss: 19.99294662475586\n",
      "Validation Loss after Epoch 180/200: 10.006387710571289\n",
      "\n",
      "Epoch 181/200, Batch 1/4, Loss: 19.9196834564209\n",
      "Epoch 181/200 completed, Average Loss: 20.018733024597168\n",
      "Validation Loss after Epoch 181/200: 10.003854274749756\n",
      "\n",
      "Epoch 182/200, Batch 1/4, Loss: 20.087244033813477\n",
      "Epoch 182/200 completed, Average Loss: 20.12998914718628\n",
      "Validation Loss after Epoch 182/200: 9.993534564971924\n",
      "\n",
      "Epoch 183/200, Batch 1/4, Loss: 19.964818954467773\n",
      "Epoch 183/200 completed, Average Loss: 19.99587917327881\n",
      "Validation Loss after Epoch 183/200: 10.031960487365723\n",
      "\n",
      "Epoch 184/200, Batch 1/4, Loss: 20.095867156982422\n",
      "Epoch 184/200 completed, Average Loss: 20.04210138320923\n",
      "Validation Loss after Epoch 184/200: 10.075738906860352\n",
      "\n",
      "Epoch 185/200, Batch 1/4, Loss: 19.97732925415039\n",
      "Epoch 185/200 completed, Average Loss: 20.075861930847168\n",
      "Validation Loss after Epoch 185/200: 10.00971508026123\n",
      "\n",
      "Epoch 186/200, Batch 1/4, Loss: 20.00149154663086\n",
      "Epoch 186/200 completed, Average Loss: 20.302288055419922\n",
      "Validation Loss after Epoch 186/200: 10.25971269607544\n",
      "\n",
      "Epoch 187/200, Batch 1/4, Loss: 20.544763565063477\n",
      "Epoch 187/200 completed, Average Loss: 20.437973976135254\n",
      "Validation Loss after Epoch 187/200: 10.014202117919922\n",
      "\n",
      "Epoch 188/200, Batch 1/4, Loss: 20.045116424560547\n",
      "Epoch 188/200 completed, Average Loss: 20.219529151916504\n",
      "Validation Loss after Epoch 188/200: 10.070669174194336\n",
      "\n",
      "Epoch 189/200, Batch 1/4, Loss: 19.937225341796875\n",
      "Epoch 189/200 completed, Average Loss: 20.32721519470215\n",
      "Validation Loss after Epoch 189/200: 10.027531623840332\n",
      "\n",
      "Epoch 190/200, Batch 1/4, Loss: 20.054336547851562\n",
      "Epoch 190/200 completed, Average Loss: 20.09304428100586\n",
      "Validation Loss after Epoch 190/200: 10.093845844268799\n",
      "\n",
      "Epoch 191/200, Batch 1/4, Loss: 20.23834228515625\n",
      "Epoch 191/200 completed, Average Loss: 20.113474369049072\n",
      "Validation Loss after Epoch 191/200: 10.031221866607666\n",
      "\n",
      "Epoch 192/200, Batch 1/4, Loss: 19.982013702392578\n",
      "Epoch 192/200 completed, Average Loss: 20.05737543106079\n",
      "Validation Loss after Epoch 192/200: 10.01243543624878\n",
      "\n",
      "Epoch 193/200, Batch 1/4, Loss: 20.099258422851562\n",
      "Epoch 193/200 completed, Average Loss: 20.116610050201416\n",
      "Validation Loss after Epoch 193/200: 10.014442443847656\n",
      "\n",
      "Epoch 194/200, Batch 1/4, Loss: 20.06708526611328\n",
      "Epoch 194/200 completed, Average Loss: 20.01314401626587\n",
      "Validation Loss after Epoch 194/200: 10.003337383270264\n",
      "\n",
      "Epoch 195/200, Batch 1/4, Loss: 19.973371505737305\n",
      "Epoch 195/200 completed, Average Loss: 20.00201177597046\n",
      "Validation Loss after Epoch 195/200: 9.990749835968018\n",
      "\n",
      "Epoch 196/200, Batch 1/4, Loss: 19.961017608642578\n",
      "Epoch 196/200 completed, Average Loss: 20.032357692718506\n",
      "Validation Loss after Epoch 196/200: 9.999234676361084\n",
      "\n",
      "Epoch 197/200, Batch 1/4, Loss: 20.101282119750977\n",
      "Epoch 197/200 completed, Average Loss: 20.052191734313965\n",
      "Validation Loss after Epoch 197/200: 9.991138458251953\n",
      "\n",
      "Epoch 198/200, Batch 1/4, Loss: 19.998260498046875\n",
      "Epoch 198/200 completed, Average Loss: 20.0398006439209\n",
      "Validation Loss after Epoch 198/200: 10.023009777069092\n",
      "\n",
      "Epoch 199/200, Batch 1/4, Loss: 20.170875549316406\n",
      "Epoch 199/200 completed, Average Loss: 20.003167152404785\n",
      "Validation Loss after Epoch 199/200: 9.993088245391846\n",
      "\n",
      "Epoch 200/200, Batch 1/4, Loss: 19.902809143066406\n",
      "Epoch 200/200 completed, Average Loss: 19.97349452972412\n",
      "Validation Loss after Epoch 200/200: 9.992225646972656\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 200  # Specify the desired number of epochs\n",
    "verbose = True  # Flag for verbosity\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    NO_model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    for batch_idx, (inputs, targets) in enumerate(train_loader):\n",
    "        inputs, targets = inputs.to(device), targets.to(device)  # Move data to the correct device\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the gradients\n",
    "        outputs = NO_model(inputs)  # Forward pass\n",
    "        loss = train_loss(outputs, targets)  # Compute the loss\n",
    "        loss.backward()  # Backward pass\n",
    "        optimizer.step()  # Update model parameters\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        if verbose and batch_idx % 10 == 0:  # Report progress every 10 batches\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx+1}/{len(train_loader)}, Loss: {loss.item()}\")\n",
    "\n",
    "    # After each epoch, report the average loss\n",
    "    avg_loss = running_loss / len(train_loader)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} completed, Average Loss: {avg_loss}\")\n",
    "\n",
    "    # Adjust learning rate according to scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    # Evaluation phase\n",
    "    NO_model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No gradients needed for validation\n",
    "        eval_loss_sum = 0.0\n",
    "        for inputs, targets in test_loader:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)  # Move data to device\n",
    "            outputs = NO_model(inputs)\n",
    "            eval_loss = eval_losses['h1'](outputs, targets)  # Can be adjusted to other loss metrics in 'eval_losses'\n",
    "            eval_loss_sum += eval_loss.item()\n",
    "        avg_eval_loss = eval_loss_sum / len(test_loader)\n",
    "        print(f\"Validation Loss after Epoch {epoch+1}/{num_epochs}: {avg_eval_loss}\\n\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:28:44.191451700Z",
     "start_time": "2024-03-25T09:28:28.381991Z"
    }
   },
   "id": "cb014eec03d642b4"
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "outputs": [],
   "source": [
    "def plot_sample_prediction(input_tensor, true_output_tensor, predicted_output_tensor):\n",
    "    \"\"\"\n",
    "    Plots the input, true output, and predicted output for one sample.\n",
    "    \n",
    "    Assumes the input is an image with shape [3, H, W] and the outputs can be reshaped to a visualizable form.\n",
    "    \"\"\"\n",
    "    fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Input\n",
    "    input_img = input_tensor.cpu().detach().numpy().transpose(1, 2, 0)\n",
    "    input_img = (input_img - input_img.min()) / (input_img.max() - input_img.min())  # Normalize to [0, 1]\n",
    "    axs[0].imshow(input_img)\n",
    "    axs[0].set_title('Input')\n",
    "    axs[0].axis('off')\n",
    "\n",
    "    # True Output\n",
    "    # Assuming the output needs reshaping or is already in a plottable shape\n",
    "    true_output_img = true_output_tensor.cpu().detach().numpy().squeeze()  # Adjust as needed\n",
    "    axs[1].imshow(true_output_img, cmap='viridis')\n",
    "    axs[1].set_title('True Output')\n",
    "    axs[1].axis('off')\n",
    "\n",
    "    # Model Prediction\n",
    "    predicted_output_img = predicted_output_tensor.cpu().detach().numpy().squeeze()  # Adjust as needed\n",
    "    axs[2].imshow(predicted_output_img, cmap='viridis')\n",
    "    axs[2].set_title('Model Prediction')\n",
    "    axs[2].axis('off')\n",
    "\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:28:46.861557Z",
     "start_time": "2024-03-25T09:28:46.844549400Z"
    }
   },
   "id": "8e88c1254d42d68d"
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "outputs": [
    {
     "data": {
      "text/plain": "<Figure size 1500x500 with 3 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# Select one sample from the DataLoader\n",
    "for inputs, targets in test_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)\n",
    "    break  # Only take the first sample for demonstration\n",
    "\n",
    "# Assuming the model is already trained and in evaluation mode\n",
    "NO_model.eval()\n",
    "with torch.no_grad():\n",
    "    predictions = NO_model(inputs)\n",
    "\n",
    "# Plotting the first sample in the batch\n",
    "sample_index = 0  # Adjust if you want to visualize a different sample in the batch\n",
    "plot_sample_prediction(inputs[sample_index], targets[sample_index].real, predictions[sample_index].real)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:28:47.886072900Z",
     "start_time": "2024-03-25T09:28:47.711024800Z"
    }
   },
   "id": "b383af5f9998381a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Obsolete code below"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "87bd8697393ceeaa"
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [],
   "source": [
    "l2loss = LpLoss(d=2, p=2)\n",
    "h1loss = H1Loss(d=2)\n",
    "\n",
    "train_loss = h1loss\n",
    "eval_losses={'h1': h1loss, 'l2': l2loss}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:05:30.456214Z",
     "start_time": "2024-03-25T09:05:30.414201Z"
    }
   },
   "id": "69eb4989fec10f46"
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### MODEL ###\n",
      " TFNO(\n",
      "  (fno_blocks): FNOBlocks(\n",
      "    (convs): SpectralConv(\n",
      "      (weight): ModuleList(\n",
      "        (0-3): 4 x ComplexTuckerTensor(shape=(16, 16, 16, 9), rank=(16, 16, 16, 9))\n",
      "      )\n",
      "    )\n",
      "    (fno_skips): ModuleList(\n",
      "      (0-3): 4 x Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    )\n",
      "  )\n",
      "  (lifting): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv2d(3, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(256, 16, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (projection): MLP(\n",
      "    (fcs): ModuleList(\n",
      "      (0): Conv2d(16, 4, kernel_size=(1, 1), stride=(1, 1))\n",
      "      (1): Conv2d(4, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      ")\n",
      "\n",
      "### OPTIMIZER ###\n",
      " Adam (\n",
      "Parameter Group 0\n",
      "    amsgrad: False\n",
      "    betas: (0.9, 0.999)\n",
      "    capturable: False\n",
      "    differentiable: False\n",
      "    eps: 1e-08\n",
      "    foreach: None\n",
      "    fused: None\n",
      "    initial_lr: 0.008\n",
      "    lr: 0.008\n",
      "    maximize: False\n",
      "    weight_decay: 0.0001\n",
      ")\n",
      "\n",
      "### SCHEDULER ###\n",
      " <torch.optim.lr_scheduler.CosineAnnealingLR object at 0x000002325A3CEC70>\n",
      "\n",
      "### LOSSES ###\n",
      "\n",
      " * Train: <neuralop.losses.data_losses.H1Loss object at 0x000002325A3CE3A0>\n",
      "\n",
      " * Test: {'h1': <neuralop.losses.data_losses.H1Loss object at 0x000002325A3CE3A0>, 'l2': <neuralop.losses.data_losses.LpLoss object at 0x000002325A3CE340>}\n"
     ]
    }
   ],
   "source": [
    "print('\\n### MODEL ###\\n', NO_model)\n",
    "print('\\n### OPTIMIZER ###\\n', optimizer)\n",
    "print('\\n### SCHEDULER ###\\n', scheduler)\n",
    "print('\\n### LOSSES ###')\n",
    "print(f'\\n * Train: {train_loss}')\n",
    "print(f'\\n * Test: {eval_losses}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:05:30.518539300Z",
     "start_time": "2024-03-25T09:05:30.428205200Z"
    }
   },
   "id": "92682cbefcc320f4"
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.override_load_to_device=False\n",
      "self.overrides_loss=False\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model=NO_model, n_epochs=1,\n",
    "                  device=device,\n",
    "                  #data_processor=data_processor,\n",
    "                  wandb_log=False,\n",
    "                  log_test_interval=3,\n",
    "                  use_distributed=False,\n",
    "                  verbose=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:05:31.376614800Z",
     "start_time": "2024-03-25T09:05:31.298093200Z"
    }
   },
   "id": "18513458e4819e03"
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Subset' object has no attribute 'inputs'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[103], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loader_wrapped\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m              \u001B[49m\u001B[43mtest_loaders\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtest_loader_wrapped\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      3\u001B[0m \u001B[43m              \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      4\u001B[0m \u001B[43m              \u001B[49m\u001B[43mscheduler\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mscheduler\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[43m              \u001B[49m\u001B[43mregularizer\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m      6\u001B[0m \u001B[43m              \u001B[49m\u001B[43mtraining_loss\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtrain_loss\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      7\u001B[0m \u001B[43m              \u001B[49m\u001B[43meval_losses\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43meval_losses\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\anaconda3\\lib\\site-packages\\neuralop\\training\\trainer.py:220\u001B[0m, in \u001B[0;36mTrainer.train\u001B[1;34m(self, train_loader, test_loaders, optimizer, scheduler, regularizer, training_loss, eval_losses)\u001B[0m\n\u001B[0;32m    215\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n\u001B[0;32m    216\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks\u001B[38;5;241m.\u001B[39mon_before_val(epoch\u001B[38;5;241m=\u001B[39mepoch, train_err\u001B[38;5;241m=\u001B[39mtrain_err, time\u001B[38;5;241m=\u001B[39mepoch_train_time, \\\n\u001B[0;32m    217\u001B[0m                            avg_loss\u001B[38;5;241m=\u001B[39mavg_loss, avg_lasso_loss\u001B[38;5;241m=\u001B[39mavg_lasso_loss)\n\u001B[1;32m--> 220\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m loader_name, loader \u001B[38;5;129;01min\u001B[39;00m \u001B[43mtest_loaders\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mitems\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m:\n\u001B[0;32m    221\u001B[0m     errors \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mevaluate(eval_losses, loader, log_prefix\u001B[38;5;241m=\u001B[39mloader_name)\n\u001B[0;32m    223\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcallbacks:\n",
      "Cell \u001B[1;32mIn[96], line 18\u001B[0m, in \u001B[0;36mDataLoaderWrapper.items\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m     16\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mitems\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;66;03m# Return a list of tuples containing the key-value pairs\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mx\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minputs\u001B[49m), (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124my\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataloader\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39moutputs)]\n",
      "\u001B[1;31mAttributeError\u001B[0m: 'Subset' object has no attribute 'inputs'"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader=train_loader_wrapped,\n",
    "              test_loaders=test_loader_wrapped,\n",
    "              optimizer=optimizer,\n",
    "              scheduler=scheduler,\n",
    "              regularizer=False,\n",
    "              training_loss=train_loss,\n",
    "              eval_losses=eval_losses)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:05:31.693869400Z",
     "start_time": "2024-03-25T09:05:31.315599200Z"
    }
   },
   "id": "ff2168e3a6dbb08c"
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "198.8743896484375\n"
     ]
    }
   ],
   "source": [
    "for inputs, targets in train_loader:\n",
    "    inputs, targets = inputs.to(device), targets.to(device)  # Move data to the same device as the model\n",
    "    outputs = NO_model(inputs)\n",
    "    loss = train_loss(outputs, targets)\n",
    "    print(loss.item())  # Print scalar value of loss to verify\n",
    "    break  # Just for demonstration, remove this in actual training\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T09:00:08.394457200Z",
     "start_time": "2024-03-25T09:00:08.343348Z"
    }
   },
   "id": "52aed256d386faab"
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "Length of batch: 2\n",
      "Type of inputs: <class 'torch.Tensor'>, Shape of inputs: torch.Size([20, 3, 32, 32])\n",
      "Type of targets: <class 'torch.Tensor'>, Shape of targets: torch.Size([20, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Check the first batch from the train_loader\n",
    "train_samples = next(iter(train_loader))\n",
    "print(type(train_samples))\n",
    "#print(train_samples[0])\n",
    "print(f\"Length of batch: {len(train_samples)}\")\n",
    "if isinstance(train_samples, (list, tuple)):\n",
    "    # Assuming the first element is inputs and the second is targets\n",
    "    print(f\"Type of inputs: {type(train_samples[0])}, Shape of inputs: {train_samples[0].shape}\")\n",
    "    print(f\"Type of targets: {type(train_samples[1])}, Shape of targets: {train_samples[1].shape}\")\n",
    "elif isinstance(train_samples, dict):\n",
    "    # If your samples are in a dictionary format\n",
    "    for key, value in train_samples.items():\n",
    "        print(f\"Key: {key}, Type of value: {type(value)}, Shape of value: {value.shape}\")\n",
    "\n",
    "# Repeat the process for test_loader if necessary\n",
    "test_samples = next(iter(test_loader))\n",
    "# Similar inspection as above for test_samples...\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:58:08.117527900Z",
     "start_time": "2024-03-25T08:58:08.097523200Z"
    }
   },
   "id": "bbbeb769cec536a9"
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs shape: torch.Size([20, 3, 32, 32])\n",
      "Targets shape: torch.Size([20, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "for batch in train_loader_wrapped:\n",
    "    inputs, targets = batch['x'], batch['y']\n",
    "    print(\"Inputs shape:\", inputs.shape)\n",
    "    print(\"Targets shape:\", targets.shape)\n",
    "    break  # Just check the first batch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-03-25T08:59:14.798048700Z",
     "start_time": "2024-03-25T08:59:14.784045900Z"
    }
   },
   "id": "9117151af39020ec"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "f7b733d93193b33d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
