Epoch,Training Loss,Validation Loss
1,0.457725586535788,0.36928041292459535
2,0.33904322062489656,0.3316640920231485
3,0.3089709913691224,0.3063058411993532
4,0.2919075429462639,0.3048536288147299
5,0.28042960834815633,0.2971464389674684
6,254988.3422549616,1.0155254844600319
7,1.0029113062681976,0.9999515791143108
8,0.9999830544805934,0.9999450973486289
9,1.0000018597222462,0.9999579127303555
10,1.0000672014600531,1.0000522177443545
11,0.9999960996144178,0.9999469393298157
12,0.9999934737170184,0.9999767111998338
13,0.9999942156164056,0.9999594542593019
14,0.9999953723076063,0.9999848262835772
15,0.9999948477220671,0.9999503688445458
16,0.9999954894736961,0.999945642789205
17,0.9999943031957687,0.9999629908871447
18,0.9999941590727565,0.9999738157101167
19,0.9999946091836673,0.9999447956370492
20,0.9999929075200333,0.9999667713784764
21,0.9999821013975008,0.9999505307980073
22,0.9999807082235983,0.9999452293673132
23,0.9999809889562449,0.9999453021848304
24,0.9999807127773253,0.9999481504350646
25,0.9999808453606065,0.9999458381416452
26,0.9999807832766802,0.9999460679730798
27,0.9999810550945097,0.9999453256313617
28,0.9999811849686495,0.9999519869894044
29,0.9999812492096186,0.9999464785380241
30,0.9999809899533916,0.9999453465103084
31,0.9999796475331668,0.9999457442332537
32,0.9999794840089955,0.9999457556610434
