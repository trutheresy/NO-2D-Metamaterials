{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Convert MATLAB Datasets to Python Format\n",
        "\n",
        "This notebook converts MATLAB `.mat` files from the OUTPUT folder to Python NumPy format compatible with existing datasets.\n",
        "\n",
        "**Usage:**\n",
        "1. Set the input folder path (where the `.mat` files are located)\n",
        "2. Set the output folder path (where converted datasets will be saved)\n",
        "3. Optionally set whether to add a prefix to test datasets\n",
        "4. Run all cells\n",
        "\n",
        "The converted datasets will have the same format as the older datasets in the `data/` folder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "import h5py\n",
        "from pathlib import Path\n",
        "from typing import Dict, Any, Tuple\n",
        "import sys\n",
        "\n",
        "# Import local modules\n",
        "try:\n",
        "    from mat73_loader import load_matlab_v73\n",
        "except ImportError:\n",
        "    try:\n",
        "        sys.path.append(str(Path.cwd() / '2d-dispersion-py'))\n",
        "        from mat73_loader import load_matlab_v73\n",
        "    except ImportError:\n",
        "        print(\"WARNING: mat73_loader not found. Make sure it's in the same directory or in 2d-dispersion-py/\")\n",
        "        raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n",
        "\n",
        "Set your input and output paths here:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input folder: D:\\Research\\NO-2D-Metamaterials\\OUTPUT\\train dataset 8\n",
            "Output folder: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\n",
            "Dataset prefix: 'train_8_'\n",
            "Complex precision: complex128\n",
            "\n",
            "Output folder ready: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# CONFIGURATION - Modify these paths as needed\n",
        "# ============================================================================\n",
        "\n",
        "# Path to folder containing .mat files (input)\n",
        "input_folder = r\"D:\\Research\\NO-2D-Metamaterials\\OUTPUT\\train dataset 8\"\n",
        "\n",
        "# Path to folder where converted datasets will be saved (output)\n",
        "output_folder = r\"D:\\Research\\NO-2D-Metamaterials\\data\\train\"\n",
        "\n",
        "# Prefix to add to converted dataset folder names (for test datasets)\n",
        "# Set to empty string \"\" or None if no prefix needed\n",
        "# For test datasets, use \"test_\" to mark them clearly\n",
        "dataset_prefix = \"train_8_\"\n",
        "\n",
        "# Complex dtype for eigenvectors (options: 'complex128' or 'complex64')\n",
        "complex_precision = 'complex128'\n",
        "\n",
        "# ============================================================================\n",
        "\n",
        "# Convert to Path objects\n",
        "input_path = Path(input_folder)\n",
        "output_path = Path(output_folder)\n",
        "\n",
        "print(f\"Input folder: {input_path}\")\n",
        "print(f\"Output folder: {output_path}\")\n",
        "print(f\"Dataset prefix: '{dataset_prefix}'\")\n",
        "print(f\"Complex precision: {complex_precision}\")\n",
        "print()\n",
        "\n",
        "# Validate input path\n",
        "if not input_path.exists():\n",
        "    raise FileNotFoundError(f\"Input folder does not exist: {input_path}\")\n",
        "\n",
        "# Create output folder if it doesn't exist\n",
        "output_path.mkdir(parents=True, exist_ok=True)\n",
        "print(f\"Output folder ready: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "## Conversion Functions\n",
        "\n",
        "def extract_scalar(val: Any) -> float:\n",
        "    \"\"\"Extract scalar value from various nested structures.\"\"\"\n",
        "    if np.isscalar(val):\n",
        "        return float(val)\n",
        "    elif isinstance(val, np.ndarray):\n",
        "        if val.ndim == 0:\n",
        "            return float(val.item())\n",
        "        else:\n",
        "            return float(val.flatten()[0])\n",
        "    else:\n",
        "        return float(val)\n",
        "\n",
        "\n",
        "def parse_const(const_raw: Dict) -> Dict[str, Any]:\n",
        "    \"\"\"Parse const structure to Python dictionary.\"\"\"\n",
        "    const = {}\n",
        "    \n",
        "    for key, val in const_raw.items():\n",
        "        if isinstance(val, np.ndarray):\n",
        "            if val.size == 1:\n",
        "                const[key] = extract_scalar(val)\n",
        "            elif val.dtype.kind == 'U' or val.dtype.kind == 'S':\n",
        "                # String array\n",
        "                const[key] = ''.join(chr(c) for c in val.flatten() if c != 0).strip()\n",
        "            else:\n",
        "                const[key] = val\n",
        "        else:\n",
        "            const[key] = val\n",
        "    \n",
        "    return const\n",
        "\n",
        "\n",
        "def embed_2const_wavelet(wavevector_x: np.ndarray, wavevector_y: np.ndarray, \n",
        "                         size: int = 32) -> np.ndarray:\n",
        "    \"\"\"Embed 2 constant wavevectors into spatial domain using wavelet-like encoding.\"\"\"\n",
        "    N_wv = len(wavevector_x)\n",
        "    waveforms = np.zeros((N_wv, size, size), dtype=np.float32)\n",
        "    \n",
        "    x = np.linspace(0, 1, size)\n",
        "    y = np.linspace(0, 1, size)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    \n",
        "    for i in range(N_wv):\n",
        "        kx = wavevector_x[i]\n",
        "        ky = wavevector_y[i]\n",
        "        waveforms[i] = np.sin(2 * np.pi * kx * X) * np.cos(2 * np.pi * ky * Y)\n",
        "    \n",
        "    return waveforms\n",
        "\n",
        "\n",
        "def embed_integer_wavelet(bands: np.ndarray, size: int = 32) -> np.ndarray:\n",
        "    \"\"\"Embed integer band indices into spatial domain using wavelet-like encoding.\"\"\"\n",
        "    N_bands = len(bands)\n",
        "    bands_fft = np.zeros((N_bands, size, size), dtype=np.float32)\n",
        "    \n",
        "    x = np.linspace(0, 1, size)\n",
        "    y = np.linspace(0, 1, size)\n",
        "    X, Y = np.meshgrid(x, y)\n",
        "    \n",
        "    for i, band in enumerate(bands):\n",
        "        bands_fft[i] = np.sin(band * np.pi * X) * np.cos(band * np.pi * Y)\n",
        "    \n",
        "    return bands_fft\n",
        "\n",
        "\n",
        "def reshape_eigenvectors_to_spatial(eigenvector_data: np.ndarray, N_pix: int) -> Tuple[np.ndarray, np.ndarray]:\n",
        "    \"\"\"Reshape eigenvector data from DOF format to spatial format and split into x/y components.\"\"\"\n",
        "    N_struct, N_eig, N_wv, N_dof = eigenvector_data.shape\n",
        "    N_nodes = int(np.sqrt(N_dof / 2))\n",
        "    \n",
        "    eigenvector_data = eigenvector_data.transpose(0, 2, 1, 3)  # (N_struct, N_wv, N_eig, N_dof)\n",
        "    \n",
        "    eigvec_x = np.zeros((N_struct, N_wv, N_eig, N_pix, N_pix), dtype=eigenvector_data.dtype)\n",
        "    eigvec_y = np.zeros((N_struct, N_wv, N_eig, N_pix, N_pix), dtype=eigenvector_data.dtype)\n",
        "    \n",
        "    for struct_idx in range(N_struct):\n",
        "        for wv_idx in range(N_wv):\n",
        "            for eig_idx in range(N_eig):\n",
        "                dof_vec = eigenvector_data[struct_idx, wv_idx, eig_idx, :]\n",
        "                u_dof = dof_vec[0::2]\n",
        "                v_dof = dof_vec[1::2]\n",
        "                eigvec_x[struct_idx, wv_idx, eig_idx, :, :] = \\\n",
        "                    u_dof.reshape(N_nodes, N_nodes)[:N_pix, :N_pix]\n",
        "                eigvec_y[struct_idx, wv_idx, eig_idx, :, :] = \\\n",
        "                    v_dof.reshape(N_nodes, N_nodes)[:N_pix, :N_pix]\n",
        "    \n",
        "    return eigvec_x, eigvec_y\n",
        "\n",
        "\n",
        "def load_mat_file(mat_path: Path) -> Dict[str, Any]:\n",
        "    \"\"\"Load MATLAB dataset from .mat file.\"\"\"\n",
        "    try:\n",
        "        data = sio.loadmat(str(mat_path), squeeze_me=False)\n",
        "        data = {k: v for k, v in data.items() if not k.startswith('__')}\n",
        "    except NotImplementedError:\n",
        "        data = load_matlab_v73(str(mat_path), verbose=False)\n",
        "    \n",
        "    return data\n",
        "\n",
        "\n",
        "def convert_mat_file(mat_path: Path, output_dir: Path, complex_precision: str = 'complex128', \n",
        "                     dataset_prefix: str = \"\"):\n",
        "    \"\"\"Convert a single MATLAB file to Python format.\"\"\"\n",
        "    # Determine complex dtype\n",
        "    if complex_precision.lower() in ('128', 'complex128'):\n",
        "        eigen_complex_dtype = np.complex128\n",
        "    elif complex_precision.lower() in ('64', 'complex64'):\n",
        "        eigen_complex_dtype = np.complex64\n",
        "    else:\n",
        "        eigen_complex_dtype = np.complex128\n",
        "    \n",
        "    # Load dataset\n",
        "    data = load_mat_file(mat_path)\n",
        "    \n",
        "    # Extract const\n",
        "    if 'const' in data:\n",
        "        const = parse_const(data['const'])\n",
        "        N_pix = int(extract_scalar(const.get('N_pix', 32)))\n",
        "        N_eig = int(extract_scalar(const.get('N_eig', 6)))\n",
        "    else:\n",
        "        const = {}\n",
        "        N_pix = 32\n",
        "        N_eig = 6\n",
        "    \n",
        "    # Extract designs\n",
        "    designs = data['designs']\n",
        "    \n",
        "    # Handle different dimension orders\n",
        "    if designs.ndim == 4:\n",
        "        if designs.shape[1] == 3:  # (N_struct, 3, N_pix, N_pix)\n",
        "            designs_first_pane = designs[:, 0, :, :]  # (N_struct, N_pix, N_pix)\n",
        "        else:\n",
        "            designs_first_pane = designs[:, :, 0, :].transpose(2, 0, 1)\n",
        "    else:\n",
        "        designs_first_pane = designs\n",
        "    \n",
        "    N_struct = designs_first_pane.shape[0]\n",
        "    \n",
        "    # Create output subdirectory for this file\n",
        "    file_stem = mat_path.stem\n",
        "    if dataset_prefix:\n",
        "        file_stem = f\"{dataset_prefix}{file_stem}\"\n",
        "    file_output_dir = output_dir / file_stem\n",
        "    file_output_dir.mkdir(exist_ok=True, parents=True)\n",
        "    \n",
        "    # Save designs (float16)\n",
        "    np.save(file_output_dir / 'designs.npy', designs_first_pane.astype(np.float16))\n",
        "    \n",
        "    # Save design_params (float64)\n",
        "    design_params = np.array([N_eig, N_pix], dtype=np.float64)\n",
        "    np.save(file_output_dir / 'design_params.npy', design_params)\n",
        "    \n",
        "    # Extract wavevector data\n",
        "    if 'WAVEVECTOR_DATA' in data:\n",
        "        wavevector_data = data['WAVEVECTOR_DATA']\n",
        "        \n",
        "        # Handle different dimension orders: (N_struct, 2, N_wv) -> (N_struct, N_wv, 2)\n",
        "        if wavevector_data.shape[1] == 2 and wavevector_data.shape[2] != 2:\n",
        "            wavevector_data = wavevector_data.transpose(0, 2, 1)  # (N_struct, N_wv, 2)\n",
        "        \n",
        "        N_wv = wavevector_data.shape[1]\n",
        "        \n",
        "        # Save wavevectors (float16)\n",
        "        np.save(file_output_dir / 'wavevectors.npy', wavevector_data.astype(np.float16))\n",
        "        \n",
        "        # Compute waveforms from first structure's wavevectors\n",
        "        waveforms = embed_2const_wavelet(\n",
        "            wavevector_data[0, :, 0],\n",
        "            wavevector_data[0, :, 1],\n",
        "            size=N_pix\n",
        "        )\n",
        "        np.save(file_output_dir / 'waveforms.npy', waveforms.astype(np.float16))\n",
        "    \n",
        "    # Extract eigenvalue data\n",
        "    if 'EIGENVALUE_DATA' in data:\n",
        "        eigenvalue_data = data['EIGENVALUE_DATA']\n",
        "        \n",
        "        # Handle dimension order: (N_struct, N_eig, N_wv) -> (N_struct, N_wv, N_eig)\n",
        "        if eigenvalue_data.shape[1] == N_eig and eigenvalue_data.shape[2] != N_eig:\n",
        "            eigenvalue_data = eigenvalue_data.transpose(0, 2, 1)  # (N_struct, N_wv, N_eig)\n",
        "        \n",
        "        # Save eigenvalue data (float16)\n",
        "        np.save(file_output_dir / 'eigenvalue_data.npy', eigenvalue_data.astype(np.float16))\n",
        "        \n",
        "        # Compute bands_fft\n",
        "        bands = np.arange(1, N_eig + 1)\n",
        "        bands_fft = embed_integer_wavelet(bands, size=N_pix)\n",
        "        np.save(file_output_dir / 'bands_fft.npy', bands_fft.astype(np.float16))\n",
        "    \n",
        "    # Extract eigenvector data\n",
        "    if 'EIGENVECTOR_DATA' in data:\n",
        "        eigenvector_data = data['EIGENVECTOR_DATA']\n",
        "        \n",
        "        # Handle structured dtype (real/imag)\n",
        "        if eigenvector_data.dtype.names and 'real' in eigenvector_data.dtype.names:\n",
        "            eigenvector_data = eigenvector_data['real'] + 1j * eigenvector_data['imag']\n",
        "        \n",
        "        # Handle dimension order: (N_struct, N_eig, N_wv, N_dof) -> (N_struct, N_wv, N_eig, N_dof)\n",
        "        if eigenvector_data.shape[1] == N_eig and eigenvector_data.shape[2] != N_eig:\n",
        "            pass  # Already in (N_struct, N_eig, N_wv, N_dof) format\n",
        "        elif eigenvector_data.shape[1] != N_eig:\n",
        "            eigenvector_data = eigenvector_data.transpose(0, 2, 1, 3)\n",
        "        \n",
        "        # Reshape to spatial format\n",
        "        eigvec_x, eigvec_y = reshape_eigenvectors_to_spatial(eigenvector_data, N_pix)\n",
        "        \n",
        "        # Save eigenvector components\n",
        "        np.save(file_output_dir / 'eigenvector_data_x.npy', eigvec_x.astype(eigen_complex_dtype))\n",
        "        np.save(file_output_dir / 'eigenvector_data_y.npy', eigvec_y.astype(eigen_complex_dtype))\n",
        "    \n",
        "    return file_output_dir\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 40 .mat files to convert\n",
            "================================================================================\n",
            "[1/40] Converting: out_binarized_1.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_1\n",
            "[2/40] Converting: out_binarized_10.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_10\n",
            "[3/40] Converting: out_binarized_11.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_11\n",
            "[4/40] Converting: out_binarized_12.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_12\n",
            "[5/40] Converting: out_binarized_13.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_13\n",
            "[6/40] Converting: out_binarized_14.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_14\n",
            "[7/40] Converting: out_binarized_15.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_15\n",
            "[8/40] Converting: out_binarized_16.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_16\n",
            "[9/40] Converting: out_binarized_17.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_17\n",
            "[10/40] Converting: out_binarized_18.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_18\n",
            "[11/40] Converting: out_binarized_19.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_19\n",
            "[12/40] Converting: out_binarized_2.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_2\n",
            "[13/40] Converting: out_binarized_20.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_20\n",
            "[14/40] Converting: out_binarized_3.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_3\n",
            "[15/40] Converting: out_binarized_4.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_4\n",
            "[16/40] Converting: out_binarized_5.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_5\n",
            "[17/40] Converting: out_binarized_6.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_6\n",
            "[18/40] Converting: out_binarized_7.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_7\n",
            "[19/40] Converting: out_binarized_8.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_8\n",
            "[20/40] Converting: out_binarized_9.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_binarized_9\n",
            "[21/40] Converting: out_continuous_1.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_1\n",
            "[22/40] Converting: out_continuous_10.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_10\n",
            "[23/40] Converting: out_continuous_11.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_11\n",
            "[24/40] Converting: out_continuous_12.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_12\n",
            "[25/40] Converting: out_continuous_13.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_13\n",
            "[26/40] Converting: out_continuous_14.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_14\n",
            "[27/40] Converting: out_continuous_15.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_15\n",
            "[28/40] Converting: out_continuous_16.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_16\n",
            "[29/40] Converting: out_continuous_17.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_17\n",
            "[30/40] Converting: out_continuous_18.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_18\n",
            "[31/40] Converting: out_continuous_19.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_19\n",
            "[32/40] Converting: out_continuous_2.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_2\n",
            "[33/40] Converting: out_continuous_20.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_20\n",
            "[34/40] Converting: out_continuous_3.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_3\n",
            "[35/40] Converting: out_continuous_4.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_4\n",
            "[36/40] Converting: out_continuous_5.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_5\n",
            "[37/40] Converting: out_continuous_6.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_6\n",
            "[38/40] Converting: out_continuous_7.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_7\n",
            "[39/40] Converting: out_continuous_8.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_8\n",
            "[40/40] Converting: out_continuous_9.mat\n",
            "    [OK] Saved to: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\\train_8_out_continuous_9\n",
            "\n",
            "================================================================================\n",
            "Conversion Summary\n",
            "================================================================================\n",
            "Input folder: D:\\Research\\NO-2D-Metamaterials\\OUTPUT\\train dataset 8\n",
            "Output folder: D:\\Research\\NO-2D-Metamaterials\\data_251117\\train\n",
            "Files converted: 40/40\n",
            "\n",
            "Successfully converted datasets (40):\n",
            "  - train_8_out_binarized_1\n",
            "  - train_8_out_binarized_10\n",
            "  - train_8_out_binarized_11\n",
            "  - train_8_out_binarized_12\n",
            "  - train_8_out_binarized_13\n",
            "  - train_8_out_binarized_14\n",
            "  - train_8_out_binarized_15\n",
            "  - train_8_out_binarized_16\n",
            "  - train_8_out_binarized_17\n",
            "  - train_8_out_binarized_18\n",
            "  - train_8_out_binarized_19\n",
            "  - train_8_out_binarized_2\n",
            "  - train_8_out_binarized_20\n",
            "  - train_8_out_binarized_3\n",
            "  - train_8_out_binarized_4\n",
            "  - train_8_out_binarized_5\n",
            "  - train_8_out_binarized_6\n",
            "  - train_8_out_binarized_7\n",
            "  - train_8_out_binarized_8\n",
            "  - train_8_out_binarized_9\n",
            "  - train_8_out_continuous_1\n",
            "  - train_8_out_continuous_10\n",
            "  - train_8_out_continuous_11\n",
            "  - train_8_out_continuous_12\n",
            "  - train_8_out_continuous_13\n",
            "  - train_8_out_continuous_14\n",
            "  - train_8_out_continuous_15\n",
            "  - train_8_out_continuous_16\n",
            "  - train_8_out_continuous_17\n",
            "  - train_8_out_continuous_18\n",
            "  - train_8_out_continuous_19\n",
            "  - train_8_out_continuous_2\n",
            "  - train_8_out_continuous_20\n",
            "  - train_8_out_continuous_3\n",
            "  - train_8_out_continuous_4\n",
            "  - train_8_out_continuous_5\n",
            "  - train_8_out_continuous_6\n",
            "  - train_8_out_continuous_7\n",
            "  - train_8_out_continuous_8\n",
            "  - train_8_out_continuous_9\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "## Run Conversion\n",
        "# This cell will convert all `.mat` files found in the input folder.\n",
        "\n",
        "# Find all .mat files in the input folder\n",
        "mat_files = sorted(input_path.glob('*.mat'))\n",
        "\n",
        "if not mat_files:\n",
        "    print(f\"ERROR: No .mat files found in {input_path}\")\n",
        "else:\n",
        "    print(f\"Found {len(mat_files)} .mat files to convert\")\n",
        "    print(\"=\" * 80)\n",
        "    \n",
        "    converted_folders = []\n",
        "    errors = []\n",
        "    \n",
        "    for i, mat_file in enumerate(mat_files, 1):\n",
        "        print(f\"[{i}/{len(mat_files)}] Converting: {mat_file.name}\")\n",
        "        try:\n",
        "            output_subdir = convert_mat_file(\n",
        "                mat_file, \n",
        "                output_path, \n",
        "                complex_precision=complex_precision,\n",
        "                dataset_prefix=dataset_prefix or \"\"\n",
        "            )\n",
        "            converted_folders.append(output_subdir.name)\n",
        "            print(f\"    [OK] Saved to: {output_subdir}\")\n",
        "        except Exception as e:\n",
        "            error_msg = f\"    ERROR converting {mat_file.name}: {e}\"\n",
        "            print(error_msg)\n",
        "            errors.append((mat_file.name, str(e)))\n",
        "            import traceback\n",
        "            traceback.print_exc()\n",
        "    \n",
        "    # Summary\n",
        "    print(\"\\n\" + \"=\" * 80)\n",
        "    print(\"Conversion Summary\")\n",
        "    print(\"=\" * 80)\n",
        "    print(f\"Input folder: {input_path}\")\n",
        "    print(f\"Output folder: {output_path}\")\n",
        "    print(f\"Files converted: {len(converted_folders)}/{len(mat_files)}\")\n",
        "    \n",
        "    if converted_folders:\n",
        "        print(f\"\\nSuccessfully converted datasets ({len(converted_folders)}):\")\n",
        "        for folder_name in converted_folders:\n",
        "            print(f\"  - {folder_name}\")\n",
        "    \n",
        "    if errors:\n",
        "        print(f\"\\nErrors ({len(errors)}):\")\n",
        "        for filename, error in errors:\n",
        "            print(f\"  - {filename}: {error}\")\n",
        "    \n",
        "    print(\"=\" * 80)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Verifying dataset: train_8_out_binarized_1\n",
            "--------------------------------------------------------------------------------\n",
            "Files present:\n",
            "  ✓ designs.npy               shape=(150, 32, 32)        dtype=float16\n",
            "  ✓ design_params.npy         shape=(2,)                 dtype=float64\n",
            "  ✓ wavevectors.npy           shape=(150, 91, 2)         dtype=float16\n",
            "  ✓ waveforms.npy             shape=(91, 32, 32)         dtype=float16\n",
            "  ✓ eigenvalue_data.npy       shape=(150, 91, 6)         dtype=float16\n",
            "  ✓ eigenvector_data_x.npy    shape=(150, 91, 6, 32, 32) dtype=complex128\n",
            "  ✓ eigenvector_data_y.npy    shape=(150, 91, 6, 32, 32) dtype=complex128\n",
            "  ✓ bands_fft.npy             shape=(6, 32, 32)          dtype=float16\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Format comparison with old dataset:\n",
            "Comparing with: set_b1_1200n\n",
            "  ✓ designs.npy               new=(150, 32, 32), old=(1200, 32, 32)\n",
            "  ✓ design_params.npy         new=(2,), old=(1, 6)\n",
            "  ? wavevectors.npy           new=(150, 91, 2), old=(1200, 325, 2)\n",
            "  ✓ waveforms.npy             new=(91, 32, 32), old=(325, 32, 32)\n",
            "  ? eigenvalue_data.npy       new=(150, 91, 6), old=(1200, 325, 6)\n",
            "  ? eigenvector_data_x.npy    new=(150, 91, 6, 32, 32), old=(1200, 325, 6, 32, 32)\n",
            "  ? eigenvector_data_y.npy    new=(150, 91, 6, 32, 32), old=(1200, 325, 6, 32, 32)\n",
            "  ✓ bands_fft.npy             new=(6, 32, 32), old=(6, 32, 32)\n"
          ]
        }
      ],
      "source": [
        "# Verify a converted dataset (use first one if available)\n",
        "if 'converted_folders' in locals() and converted_folders:\n",
        "    verify_folder = output_path / converted_folders[0]\n",
        "    print(f\"Verifying dataset: {verify_folder.name}\")\n",
        "    print(\"-\" * 80)\n",
        "    \n",
        "    # Check all expected files exist\n",
        "    expected_files = [\n",
        "        'designs.npy',\n",
        "        'design_params.npy',\n",
        "        'wavevectors.npy',\n",
        "        'waveforms.npy',\n",
        "        'eigenvalue_data.npy',\n",
        "        'eigenvector_data_x.npy',\n",
        "        'eigenvector_data_y.npy',\n",
        "        'bands_fft.npy'\n",
        "    ]\n",
        "    \n",
        "    print(\"Files present:\")\n",
        "    for fname in expected_files:\n",
        "        fpath = verify_folder / fname\n",
        "        if fpath.exists():\n",
        "            arr = np.load(fpath)\n",
        "            print(f\"  ✓ {fname:25s} shape={str(arr.shape):20s} dtype={arr.dtype}\")\n",
        "        else:\n",
        "            print(f\"  ✗ {fname:25s} MISSING\")\n",
        "    \n",
        "    # Compare with old dataset format\n",
        "    print(\"\\n\" + \"-\" * 80)\n",
        "    print(\"Format comparison with old dataset:\")\n",
        "    old_dataset_path = Path(r\"D:\\Research\\NO-2D-Metamaterials\\data\\set_b1_1200n\")\n",
        "    if old_dataset_path.exists():\n",
        "        print(f\"Comparing with: {old_dataset_path.name}\")\n",
        "        for fname in expected_files:\n",
        "            new_fpath = verify_folder / fname\n",
        "            old_fpath = old_dataset_path / fname\n",
        "            if new_fpath.exists() and old_fpath.exists():\n",
        "                new_arr = np.load(new_fpath)\n",
        "                old_arr = np.load(old_fpath)\n",
        "                shape_match = new_arr.shape[1:] == old_arr.shape[1:] if len(new_arr.shape) == len(old_arr.shape) else False\n",
        "                dtype_match = new_arr.dtype == old_arr.dtype\n",
        "                status = \"✓\" if (shape_match or fname in ['design_params.npy']) and dtype_match else \"?\"\n",
        "                print(f\"  {status} {fname:25s} new={new_arr.shape}, old={old_arr.shape}\")\n",
        "    else:\n",
        "        print(\"Old dataset not found for comparison\")\n",
        "else:\n",
        "    print(\"No datasets converted yet. Run the conversion cell first.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "NO_2D_Metamaterials",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
